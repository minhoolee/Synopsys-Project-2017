Retrieving train, validation, and test data
Building the model
Compiling model
Saving models in json and yaml format to models/json/conv_net_12.json and  models/yaml/conv_net_12.yaml
Saving weights to models/weights/conv_net_12.hdf5 and epoch logs to models/run_logs/conv_net_12.csv
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 64)       832         convolution1d_input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 998, 64)       0           convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 64)       256         activation_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)    (None, 499, 64)       0           batchnormalization_1[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 499, 64)       0           maxpooling1d_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 497, 128)      24704       dropout_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 497, 128)      0           convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 497, 128)      512         activation_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)    (None, 248, 128)      0           batchnormalization_2[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 248, 128)      0           maxpooling1d_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 246, 256)      98560       dropout_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 246, 256)      0           convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 246, 256)      1024        activation_3[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)    (None, 123, 256)      0           batchnormalization_3[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 123, 256)      0           maxpooling1d_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 119, 512)      655872      dropout_3[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)        (None, 119, 512)      0           convolution1d_4[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 119, 512)      2048        activation_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_4 (MaxPooling1D)    (None, 59, 512)       0           batchnormalization_4[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 59, 512)       0           maxpooling1d_4[0][0]
____________________________________________________________________________________________________
convolution1d_5 (Convolution1D)  (None, 55, 512)       1311232     dropout_4[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)        (None, 55, 512)       0           convolution1d_5[0][0]
____________________________________________________________________________________________________
maxpooling1d_5 (MaxPooling1D)    (None, 27, 512)       0           activation_5[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 13824)         0           maxpooling1d_5[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1024)          14156800    flatten_1[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)        (None, 1024)          0           dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_5 (BatchNorma (None, 1024)          4096        activation_6[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 1024)          0           batchnormalization_5[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 919)           941975      dropout_5[0][0]
____________________________________________________________________________________________________
activation_7 (Activation)        (None, 919)           0           dense_2[0][0]
====================================================================================================
Total params: 17,197,911
Trainable params: 17,193,943
Non-trainable params: 3,968
____________________________________________________________________________________________________

The date is 02/11/2017
The time is 06:23:53 PM

Loading weights from models/weights/conv_net_12.hdf5 if it exists
Running at most 70 epochs
Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9773Epoch 00000: val_loss improved from inf to 0.06134, saving model to models/weights/conv_net_12.hdf5
2200000/2200000 [==============================] - 3037s - loss: 0.0787 - acc: 0.9773 - val_loss: 0.0613 - val_acc: 0.9822
Epoch 2/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9797Epoch 00001: val_loss improved from 0.06134 to 0.05993, saving model to models/weights/conv_net_12.hdf5
2200000/2200000 [==============================] - 3036s - loss: 0.0698 - acc: 0.9797 - val_loss: 0.0599 - val_acc: 0.9823
Epoch 3/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9799Epoch 00002: val_loss improved from 0.05993 to 0.05761, saving model to models/weights/conv_net_12.hdf5
2200000/2200000 [==============================] - 3036s - loss: 0.0682 - acc: 0.9799 - val_loss: 0.0576 - val_acc: 0.9827
Epoch 4/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9801Epoch 00003: val_loss improved from 0.05761 to 0.05713, saving model to models/weights/conv_net_12.hdf5
2200000/2200000 [==============================] - 3036s - loss: 0.0672 - acc: 0.9801 - val_loss: 0.0571 - val_acc: 0.9827
Epoch 5/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9802Epoch 00004: val_loss did not improve
2200000/2200000 [==============================] - 3036s - loss: 0.0665 - acc: 0.9802 - val_loss: 0.0574 - val_acc: 0.9825
Epoch 6/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9803Epoch 00005: val_loss improved from 0.05713 to 0.05654, saving model to models/weights/conv_net_12.hdf5
2200000/2200000 [==============================] - 3036s - loss: 0.0659 - acc: 0.9803 - val_loss: 0.0565 - val_acc: 0.9826
Epoch 7/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9803Epoch 00006: val_loss improved from 0.05654 to 0.05634, saving model to models/weights/conv_net_12.hdf5
2200000/2200000 [==============================] - 3036s - loss: 0.0654 - acc: 0.9803 - val_loss: 0.0563 - val_acc: 0.9828
Epoch 8/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9804Epoch 00007: val_loss improved from 0.05634 to 0.05590, saving model to models/weights/conv_net_12.hdf5
2200000/2200000 [==============================] - 3038s - loss: 0.0650 - acc: 0.9804 - val_loss: 0.0559 - val_acc: 0.9828
Epoch 9/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9805Epoch 00008: val_loss improved from 0.05590 to 0.05584, saving model to models/weights/conv_net_12.hdf5
2200000/2200000 [==============================] - 3037s - loss: 0.0647 - acc: 0.9805 - val_loss: 0.0558 - val_acc: 0.9828
Epoch 10/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9805Epoch 00009: val_loss did not improve
2200000/2200000 [==============================] - 3037s - loss: 0.0643 - acc: 0.9805 - val_loss: 0.0559 - val_acc: 0.9828
Epoch 11/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9806Epoch 00010: val_loss improved from 0.05584 to 0.05573, saving model to models/weights/conv_net_12.hdf5
2200000/2200000 [==============================] - 3038s - loss: 0.0641 - acc: 0.9806 - val_loss: 0.0557 - val_acc: 0.9828
Epoch 12/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9806Epoch 00011: val_loss did not improve
2200000/2200000 [==============================] - 3037s - loss: 0.0638 - acc: 0.9806 - val_loss: 0.0558 - val_acc: 0.9828
Epoch 13/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9807Epoch 00012: val_loss did not improve
2200000/2200000 [==============================] - 3037s - loss: 0.0636 - acc: 0.9807 - val_loss: 0.0558 - val_acc: 0.9828
Epoch 14/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9807Epoch 00013: val_loss did not improve
2200000/2200000 [==============================] - 3037s - loss: 0.0634 - acc: 0.9807 - val_loss: 0.0561 - val_acc: 0.9826
Epoch 15/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9807Epoch 00014: val_loss improved from 0.05573 to 0.05562, saving model to models/weights/conv_net_12.hdf5
2200000/2200000 [==============================] - 3037s - loss: 0.0633 - acc: 0.9807 - val_loss: 0.0556 - val_acc: 0.9828
Epoch 16/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9808Epoch 00015: val_loss did not improve
2200000/2200000 [==============================] - 3037s - loss: 0.0631 - acc: 0.9808 - val_loss: 0.0556 - val_acc: 0.9828
Epoch 17/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9808Epoch 00016: val_loss did not improve
2200000/2200000 [==============================] - 3036s - loss: 0.0629 - acc: 0.9808 - val_loss: 0.0560 - val_acc: 0.9827
Epoch 18/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9808Epoch 00017: val_loss did not improve
2200000/2200000 [==============================] - 3037s - loss: 0.0627 - acc: 0.9808 - val_loss: 0.0558 - val_acc: 0.9827
Epoch 19/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9808Epoch 00018: val_loss did not improve
2200000/2200000 [==============================] - 3037s - loss: 0.0626 - acc: 0.9808 - val_loss: 0.0558 - val_acc: 0.9828
Epoch 20/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9809Epoch 00019: val_loss improved from 0.05562 to 0.05550, saving model to models/weights/conv_net_12.hdf5
2200000/2200000 [==============================] - 3038s - loss: 0.0625 - acc: 0.9809 - val_loss: 0.0555 - val_acc: 0.9827
Epoch 21/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9809Epoch 00020: val_loss did not improve
2200000/2200000 [==============================] - 3037s - loss: 0.0624 - acc: 0.9809 - val_loss: 0.0558 - val_acc: 0.9827
Epoch 22/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9809Epoch 00021: val_loss did not improve
2200000/2200000 [==============================] - 3037s - loss: 0.0622 - acc: 0.9809 - val_loss: 0.0556 - val_acc: 0.9828
Epoch 23/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9809Epoch 00022: val_loss did not improve
2200000/2200000 [==============================] - 3063s - loss: 0.0621 - acc: 0.9809 - val_loss: 0.0558 - val_acc: 0.9827
Epoch 24/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9810Epoch 00023: val_loss improved from 0.05550 to 0.05536, saving model to models/weights/conv_net_12.hdf5
2200000/2200000 [==============================] - 3044s - loss: 0.0620 - acc: 0.9810 - val_loss: 0.0554 - val_acc: 0.9827
Epoch 25/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9810Epoch 00024: val_loss did not improve
2200000/2200000 [==============================] - 3044s - loss: 0.0619 - acc: 0.9810 - val_loss: 0.0555 - val_acc: 0.9827
Epoch 26/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9810Epoch 00025: val_loss did not improve
2200000/2200000 [==============================] - 3044s - loss: 0.0618 - acc: 0.9810 - val_loss: 0.0557 - val_acc: 0.9827
Epoch 27/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9810Epoch 00026: val_loss did not improve
2200000/2200000 [==============================] - 3044s - loss: 0.0617 - acc: 0.9810 - val_loss: 0.0555 - val_acc: 0.9827
