2017-03-16 22:28:56,663 src.models.keras_model_utils INFO     Creating model from conv_net()
2017-03-16 22:28:56,663 src.models.create_models INFO     Building the model
2017-03-16 22:28:58,253 src.models.create_models INFO     Compiling model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_1 (InputLayer)             (None, 1000, 4)       0
____________________________________________________________________________________________________
convolution1d_1 (Convolution1D)  (None, 998, 64)       832         input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 998, 64)       0           convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 64)       256         activation_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)    (None, 499, 64)       0           batchnormalization_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 497, 64)       12352       maxpooling1d_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 497, 64)       0           convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 497, 64)       256         activation_2[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 497, 64)       0           batchnormalization_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)    (None, 248, 64)       0           dropout_1[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 246, 128)      24704       maxpooling1d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 246, 128)      0           convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 246, 128)      512         activation_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 244, 128)      49280       batchnormalization_3[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)        (None, 244, 128)      0           convolution1d_4[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 244, 128)      512         activation_4[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 244, 128)      0           batchnormalization_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)    (None, 122, 128)      0           dropout_2[0][0]
____________________________________________________________________________________________________
convolution1d_5 (Convolution1D)  (None, 120, 256)      98560       maxpooling1d_3[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)        (None, 120, 256)      0           convolution1d_5[0][0]
____________________________________________________________________________________________________
batchnormalization_5 (BatchNorma (None, 120, 256)      1024        activation_5[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 120, 256)      0           batchnormalization_5[0][0]
____________________________________________________________________________________________________
convolution1d_6 (Convolution1D)  (None, 118, 256)      196864      dropout_3[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)        (None, 118, 256)      0           convolution1d_6[0][0]
____________________________________________________________________________________________________
batchnormalization_6 (BatchNorma (None, 118, 256)      1024        activation_6[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 118, 256)      0           batchnormalization_6[0][0]
____________________________________________________________________________________________________
maxpooling1d_4 (MaxPooling1D)    (None, 59, 256)       0           dropout_4[0][0]
____________________________________________________________________________________________________
batchnormalization_7 (BatchNorma (None, 59, 256)       1024        maxpooling1d_4[0][0]
____________________________________________________________________________________________________
activation_7 (Activation)        (None, 59, 256)       0           batchnormalization_7[0][0]
____________________________________________________________________________________________________
convolution1d_7 (Convolution1D)  (None, 30, 64)        49152       activation_7[0][0]
____________________________________________________________________________________________________
batchnormalization_8 (BatchNorma (None, 30, 64)        256         convolution1d_7[0][0]
____________________________________________________________________________________________________
activation_8 (Activation)        (None, 30, 64)        0           batchnormalization_8[0][0]
____________________________________________________________________________________________________
convolution1d_8 (Convolution1D)  (None, 30, 64)        12288       activation_8[0][0]
____________________________________________________________________________________________________
convolution1d_9 (Convolution1D)  (None, 30, 64)        16384       activation_7[0][0]
____________________________________________________________________________________________________
merge_1 (Merge)                  (None, 30, 64)        0           convolution1d_8[0][0]
                                                                   convolution1d_9[0][0]
____________________________________________________________________________________________________
batchnormalization_9 (BatchNorma (None, 30, 64)        256         merge_1[0][0]
____________________________________________________________________________________________________
activation_9 (Activation)        (None, 30, 64)        0           batchnormalization_9[0][0]
____________________________________________________________________________________________________
convolution1d_10 (Convolution1D) (None, 30, 64)        12288       activation_9[0][0]
____________________________________________________________________________________________________
batchnormalization_10 (BatchNorm (None, 30, 64)        256         convolution1d_10[0][0]
____________________________________________________________________________________________________
activation_10 (Activation)       (None, 30, 64)        0           batchnormalization_10[0][0]
____________________________________________________________________________________________________
convolution1d_11 (Convolution1D) (None, 30, 64)        12288       activation_10[0][0]
____________________________________________________________________________________________________
merge_2 (Merge)                  (None, 30, 64)        0           convolution1d_11[0][0]
                                                                   merge_1[0][0]
____________________________________________________________________________________________________
batchnormalization_11 (BatchNorm (None, 30, 64)        256         merge_2[0][0]
____________________________________________________________________________________________________
activation_11 (Activation)       (None, 30, 64)        0           batchnormalization_11[0][0]
____________________________________________________________________________________________________
maxpooling1d_5 (MaxPooling1D)    (None, 15, 64)        0           activation_11[0][0]
____________________________________________________________________________________________________
bidirectional_1 (Bidirectional)  (None, 15, 512)       493056      maxpooling1d_5[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 7680)          0           bidirectional_1[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1024)          7865344     flatten_1[0][0]
____________________________________________________________________________________________________
activation_12 (Activation)       (None, 1024)          0           dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_12 (BatchNorm (None, 1024)          4096        activation_12[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 1024)          0           batchnormalization_12[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 919)           941975      dropout_5[0][0]
____________________________________________________________________________________________________
activation_13 (Activation)       (None, 919)           0           dense_2[0][0]
====================================================================================================
Total params: 9,795,095
Trainable params: 9,790,231
Non-trainable params: 4,864
____________________________________________________________________________________________________
2017-03-16 22:28:59,996 __main__     INFO     Retrieving train data...
2017-03-16 22:30:05,166 __main__     INFO     Retrieving validation data...
2017-03-16 22:30:05,260 __main__     INFO     Saving model to file system...
2017-03-16 22:30:05,261 src.models.keras_model_utils INFO     Saving models/json/conv_net_large_res_1.json to models/json/conv_net_large_res_1.json.old
2017-03-16 22:30:05,262 src.models.keras_model_utils INFO     Saving model to models/json/conv_net_large_res_1.json
2017-03-16 22:30:05,268 src.models.keras_model_utils INFO     Saving models/yaml/conv_net_large_res_1.yaml to models/yaml/conv_net_large_res_1.yaml.old
2017-03-16 22:30:05,268 src.models.keras_model_utils INFO     Saving model to models/yaml/conv_net_large_res_1.yaml
2017-03-16 22:30:05,308 __main__     INFO     Loading model weights...
2017-03-16 22:30:05,309 __main__     INFO     The date is 03/16/2017
2017-03-16 22:30:05,309 __main__     INFO     The time is 10:30:05 PM

2017-03-16 22:30:05,309 __main__     INFO     Training model...
2017-03-16 22:30:05,310 src.models.keras_model_utils INFO     Saving models/csv/conv_net_large_res_1.csv to models/csv/conv_net_large_res_1.csv.old
2017-03-16 22:30:05,310 src.models.keras_model_utils INFO     Running at most 70 epochs
2017-03-16 22:30:05,310 src.models.keras_model_utils INFO     Saving weights to models/weights/conv_net_large_res_1.hdf5 and epoch logs to models/csv/conv_net_large_res_1.csv
Train on 4400000 samples, validate on 8000 samples
Epoch 1/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9780Epoch 00000: val_loss improved from inf to 0.06363, saving model to models/weights/conv_net_large_res_1.hdf5
4400000/4400000 [==============================] - 5252s - loss: 0.0775 - acc: 0.9780 - val_loss: 0.0636 - val_acc: 0.9819
Epoch 2/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9797Epoch 00001: val_loss improved from 0.06363 to 0.05974, saving model to models/weights/conv_net_large_res_1.hdf5
4400000/4400000 [==============================] - 5251s - loss: 0.0702 - acc: 0.9797 - val_loss: 0.0597 - val_acc: 0.9826
Epoch 3/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9799Epoch 00002: val_loss improved from 0.05974 to 0.05934, saving model to models/weights/conv_net_large_res_1.hdf5
4400000/4400000 [==============================] - 5249s - loss: 0.0691 - acc: 0.9799 - val_loss: 0.0593 - val_acc: 0.9824
Epoch 4/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9800Epoch 00003: val_loss did not improve
4400000/4400000 [==============================] - 5277s - loss: 0.0681 - acc: 0.9800 - val_loss: 0.0596 - val_acc: 0.9823
Epoch 5/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9801Epoch 00004: val_loss improved from 0.05934 to 0.05934, saving model to models/weights/conv_net_large_res_1.hdf5
4400000/4400000 [==============================] - 5252s - loss: 0.0676 - acc: 0.9801 - val_loss: 0.0593 - val_acc: 0.9825
Epoch 6/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9801Epoch 00005: val_loss improved from 0.05934 to 0.05845, saving model to models/weights/conv_net_large_res_1.hdf5
4400000/4400000 [==============================] - 5246s - loss: 0.0672 - acc: 0.9801 - val_loss: 0.0584 - val_acc: 0.9826
Epoch 7/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9802Epoch 00006: val_loss did not improve
4400000/4400000 [==============================] - 5281s - loss: 0.0670 - acc: 0.9802 - val_loss: 0.0594 - val_acc: 0.9824
Epoch 8/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9802Epoch 00007: val_loss improved from 0.05845 to 0.05785, saving model to models/weights/conv_net_large_res_1.hdf5
4400000/4400000 [==============================] - 5244s - loss: 0.0668 - acc: 0.9802 - val_loss: 0.0579 - val_acc: 0.9829
Epoch 9/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9802Epoch 00008: val_loss improved from 0.05785 to 0.05721, saving model to models/weights/conv_net_large_res_1.hdf5
4400000/4400000 [==============================] - 5249s - loss: 0.0666 - acc: 0.9802 - val_loss: 0.0572 - val_acc: 0.9829
Epoch 10/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9803Epoch 00009: val_loss improved from 0.05721 to 0.05720, saving model to models/weights/conv_net_large_res_1.hdf5
4400000/4400000 [==============================] - 5284s - loss: 0.0664 - acc: 0.9803 - val_loss: 0.0572 - val_acc: 0.9829
Epoch 11/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9803Epoch 00010: val_loss did not improve
4400000/4400000 [==============================] - 5246s - loss: 0.0663 - acc: 0.9803 - val_loss: 0.0580 - val_acc: 0.9829
Epoch 12/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9803Epoch 00011: val_loss did not improve
4400000/4400000 [==============================] - 5278s - loss: 0.0662 - acc: 0.9803 - val_loss: 0.0579 - val_acc: 0.9827
Epoch 13/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9803Epoch 00012: val_loss did not improve
4400000/4400000 [==============================] - 5258s - loss: 0.0661 - acc: 0.9803 - val_loss: 0.0575 - val_acc: 0.9831
Epoch 14/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9803Epoch 00013: val_loss did not improve
4400000/4400000 [==============================] - 5368s - loss: 0.0659 - acc: 0.9803 - val_loss: 0.0582 - val_acc: 0.9829
