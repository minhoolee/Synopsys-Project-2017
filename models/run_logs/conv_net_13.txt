Creating model from conv_net()
Building the model
Compiling model
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 64)       832	   convolution1d_input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 998, 64)       0	   convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 64)       256	   activation_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 996, 64)       12352	   batchnormalization_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)	 (None, 996, 64)       0	   convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 996, 64)       256	   activation_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)	 (None, 498, 64)       0	   batchnormalization_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 496, 128)      24704	   maxpooling1d_1[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)	 (None, 496, 128)      0	   convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 496, 128)      512	   activation_3[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)		 (None, 496, 128)      0	   batchnormalization_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 494, 128)      49280	   dropout_1[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)	 (None, 494, 128)      0	   convolution1d_4[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 494, 128)      512	   activation_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)	 (None, 247, 128)      0	   batchnormalization_4[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)		 (None, 247, 128)      0	   maxpooling1d_2[0][0]
____________________________________________________________________________________________________
convolution1d_5 (Convolution1D)  (None, 243, 256)      164096	   dropout_2[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)	 (None, 243, 256)      0	   convolution1d_5[0][0]
____________________________________________________________________________________________________
batchnormalization_5 (BatchNorma (None, 243, 256)      1024	   activation_5[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)		 (None, 243, 256)      0	   batchnormalization_5[0][0]
____________________________________________________________________________________________________
convolution1d_6 (Convolution1D)  (None, 239, 256)      327936	   dropout_3[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)	 (None, 239, 256)      0	   convolution1d_6[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)	 (None, 119, 256)      0	   activation_6[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)		 (None, 30464)	       0	   maxpooling1d_3[0][0]
____________________________________________________________________________________________________
dense_1 (Dense) 		 (None, 1024)	       31196160    flatten_1[0][0]
____________________________________________________________________________________________________
activation_7 (Activation)	 (None, 1024)	       0	   dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_6 (BatchNorma (None, 1024)	       4096	   activation_7[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)		 (None, 1024)	       0	   batchnormalization_6[0][0]
____________________________________________________________________________________________________
dense_2 (Dense) 		 (None, 919)	       941975	   dropout_4[0][0]
____________________________________________________________________________________________________
activation_8 (Activation)	 (None, 919)	       0	   dense_2[0][0]
====================================================================================================
Total params: 32,723,991
Trainable params: 32,720,663
Non-trainable params: 3,328
____________________________________________________________________________________________________
Saving models in json and yaml format to models/json/conv_net_13.json and  models/yaml/conv_net_13.yaml
Saving weights to models/weights/conv_net_13.hdf5 and epoch logs to models/csv/conv_net_13.csv
Saving models/json/conv_net_13.json to models/json/conv_net_13.json.old
Saving models/yaml/conv_net_13.yaml to models/yaml/conv_net_13.yaml.old
Retrieving train, validation, and test data

The date is 02/13/2017
The time is 12:12:32 AM

Loading weights from models/weights/conv_net_13.hdf5 if it exists
Saving models/csv/conv_net_13.csv to models/csv/conv_net_13.csv.old
Running at most 70 epochs
Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.07766--acc::0.9775Epoch 00000: val_loss improved from inf to 0.05935, saving model to models/weights/conv_net_13.hdf5
2200000/2200000 [==============================] - 3615s - loss: 0.0776 - acc: 0.9775 - val_loss: 0.0594 - val_acc: 0.9824
Epoch 2/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06788--acc::0.9799Epoch 00001: val_loss improved from 0.05935 to 0.05838, saving model to models/weights/conv_net_13.hdf5
2200000/2200000 [==============================] - 3616s - loss: 0.0678 - acc: 0.9799 - val_loss: 0.0584 - val_acc: 0.9825
Epoch 3/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06622--acc::0.9801Epoch 00002: val_loss improved from 0.05838 to 0.05678, saving model to models/weights/conv_net_13.hdf5
2200000/2200000 [==============================] - 3615s - loss: 0.0662 - acc: 0.9801 - val_loss: 0.0568 - val_acc: 0.9827
Epoch 4/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06511--acc::0.9803Epoch 00003: val_loss improved from 0.05678 to 0.05661, saving model to models/weights/conv_net_13.hdf5
2200000/2200000 [==============================] - 3615s - loss: 0.0651 - acc: 0.9803 - val_loss: 0.0566 - val_acc: 0.9827
Epoch 5/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06444--acc::0.9804Epoch 00004: val_loss improved from 0.05661 to 0.05586, saving model to models/weights/conv_net_13.hdf5
2200000/2200000 [==============================] - 3615s - loss: 0.0644 - acc: 0.9804 - val_loss: 0.0559 - val_acc: 0.9828
Epoch 6/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06399--acc::0.9805Epoch 00005: val_loss did not improve
2200000/2200000 [==============================] - 3613s - loss: 0.0639 - acc: 0.9805 - val_loss: 0.0560 - val_acc: 0.9828
Epoch 7/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06344--acc::0.9805Epoch 00006: val_loss improved from 0.05586 to 0.05535, saving model to models/weights/conv_net_13.hdf5
2200000/2200000 [==============================] - 3615s - loss: 0.0634 - acc: 0.9805 - val_loss: 0.0554 - val_acc: 0.9829
Epoch 8/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06300--acc::0.9806Epoch 00007: val_loss did not improve
2200000/2200000 [==============================] - 3615s - loss: 0.0630 - acc: 0.9806 - val_loss: 0.0560 - val_acc: 0.9828
Epoch 9/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06266--acc::0.9807Epoch 00008: val_loss did not improve
2200000/2200000 [==============================] - 3614s - loss: 0.0626 - acc: 0.9807 - val_loss: 0.0556 - val_acc: 0.9829
Epoch 10/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06233--acc::0.9807Epoch 00009: val_loss did not improve
2200000/2200000 [==============================] - 3615s - loss: 0.0623 - acc: 0.9807 - val_loss: 0.0563 - val_acc: 0.9826
Epoch 11/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06200--acc::0.9808Epoch 00010: val_loss did not improve
2200000/2200000 [==============================] - 3614s - loss: 0.0620 - acc: 0.9808 - val_loss: 0.0563 - val_acc: 0.9828
Epoch 12/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06188--acc::0.9808Epoch 00011: val_loss improved from 0.05535 to 0.05532, saving model to models/weights/conv_net_13.hdf5
2200000/2200000 [==============================] - 3615s - loss: 0.0618 - acc: 0.9808 - val_loss: 0.0553 - val_acc: 0.9829
Epoch 13/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06155--acc::0.9809Epoch 00012: val_loss improved from 0.05532 to 0.05498, saving model to models/weights/conv_net_13.hdf5
2200000/2200000 [==============================] - 3616s - loss: 0.0615 - acc: 0.9809 - val_loss: 0.0550 - val_acc: 0.9830
Epoch 14/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06133--acc::0.9809Epoch 00013: val_loss improved from 0.05498 to 0.05477, saving model to models/weights/conv_net_13.hdf5
2200000/2200000 [==============================] - 3614s - loss: 0.0613 - acc: 0.9809 - val_loss: 0.0548 - val_acc: 0.9830
Epoch 15/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06111--acc::0.9810Epoch 00014: val_loss did not improve
2200000/2200000 [==============================] - 3614s - loss: 0.0611 - acc: 0.9810 - val_loss: 0.0551 - val_acc: 0.9830
Epoch 16/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06100--acc::0.9810Epoch 00015: val_loss did not improve
2200000/2200000 [==============================] - 3615s - loss: 0.0610 - acc: 0.9810 - val_loss: 0.0551 - val_acc: 0.9829
Epoch 17/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06088--acc::0.9810Epoch 00016: val_loss did not improve
2200000/2200000 [==============================] - 3611s - loss: 0.0608 - acc: 0.9810 - val_loss: 0.0555 - val_acc: 0.9829
Epoch 18/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06077--acc::0.9811Epoch 00017: val_loss improved from 0.05477 to 0.05439, saving model to models/weights/conv_net_13.hdf5
2200000/2200000 [==============================] - 3608s - loss: 0.0607 - acc: 0.9811 - val_loss: 0.0544 - val_acc: 0.9831
Epoch 19/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06055--acc::0.9811Epoch 00018: val_loss did not improve
2200000/2200000 [==============================] - 3608s - loss: 0.0605 - acc: 0.9811 - val_loss: 0.0551 - val_acc: 0.9830
Epoch 20/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06044--acc::0.9811Epoch 00019: val_loss did not improve
2200000/2200000 [==============================] - 3607s - loss: 0.0604 - acc: 0.9811 - val_loss: 0.0547 - val_acc: 0.9829
Epoch 21/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06033--acc::0.9812Epoch 00020: val_loss did not improve
2200000/2200000 [==============================] - 3607s - loss: 0.0603 - acc: 0.9812 - val_loss: 0.0555 - val_acc: 0.9828
Epoch 22/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06022--acc::0.9812Epoch 00021: val_loss did not improve
2200000/2200000 [==============================] - 3607s - loss: 0.0602 - acc: 0.9812 - val_loss: 0.0554 - val_acc: 0.9829
Epoch 23/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06011--acc::0.9812Epoch 00022: val_loss did not improve
2200000/2200000 [==============================] - 3606s - loss: 0.0601 - acc: 0.9812 - val_loss: 0.0551 - val_acc: 0.9829
Epoch 24/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06000--acc::0.9812Epoch 00023: val_loss did not improve
2200000/2200000 [==============================] - 3607s - loss: 0.0600 - acc: 0.9812 - val_loss: 0.0549 - val_acc: 0.9829
Epoch 00023: early stopping
455008/455024 [============================>.] - ETA: 0s
[0.059843193283373668, 0.98149812621420418]
