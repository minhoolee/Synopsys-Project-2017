Creating model from conv_net()
Building the model
Compiling model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 64)       832         convolution1d_input_1[0][0]
____________________________________________________________________________________________________
prelu_1 (PReLU)                  (None, 998, 64)       63872       convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 64)       256         prelu_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 996, 64)       12352       batchnormalization_1[0][0]
____________________________________________________________________________________________________
prelu_2 (PReLU)                  (None, 996, 64)       63744       convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 996, 64)       256         prelu_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)    (None, 498, 64)       0           batchnormalization_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 496, 128)      24704       maxpooling1d_1[0][0]
____________________________________________________________________________________________________
prelu_3 (PReLU)                  (None, 496, 128)      63488       convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 496, 128)      512         prelu_3[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 496, 128)      0           batchnormalization_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 494, 128)      49280       dropout_1[0][0]
____________________________________________________________________________________________________
prelu_4 (PReLU)                  (None, 494, 128)      63232       convolution1d_4[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 494, 128)      512         prelu_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)    (None, 247, 128)      0           batchnormalization_4[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 247, 128)      0           maxpooling1d_2[0][0]
____________________________________________________________________________________________________
convolution1d_5 (Convolution1D)  (None, 243, 256)      164096      dropout_2[0][0]
____________________________________________________________________________________________________
prelu_5 (PReLU)                  (None, 243, 256)      62208       convolution1d_5[0][0]
____________________________________________________________________________________________________
batchnormalization_5 (BatchNorma (None, 243, 256)      1024        prelu_5[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 243, 256)      0           batchnormalization_5[0][0]
____________________________________________________________________________________________________
convolution1d_6 (Convolution1D)  (None, 239, 256)      327936      dropout_3[0][0]
____________________________________________________________________________________________________
prelu_6 (PReLU)                  (None, 239, 256)      61184       convolution1d_6[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)    (None, 119, 256)      0           prelu_6[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 30464)         0           maxpooling1d_3[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1024)          31196160    flatten_1[0][0]
____________________________________________________________________________________________________
prelu_7 (PReLU)                  (None, 1024)          1024        dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_6 (BatchNorma (None, 1024)          4096        prelu_7[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 1024)          0           batchnormalization_6[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 919)           941975      dropout_4[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 919)           0           dense_2[0][0]
====================================================================================================
Total params: 33,102,743
Trainable params: 33,099,415
Non-trainable params: 3,328
____________________________________________________________________________________________________
Saving models in json and yaml format to models/json/conv_net_22.json and  models/yaml/conv_net_22.yaml
Saving weights to models/weights/conv_net_22.hdf5 and epoch logs to models/csv/conv_net_22.csv
Retrieving train, validation, and test data

The date is 02/22/2017
The time is 08:26:55 AM

Loading weights from models/weights/conv_net_22.hdf5 if it exists
Running at most 70 epochs
Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9773Epoch 00000: val_loss improved from inf to 0.06286, saving model to models/weights/conv_net_22.hdf5
2200000/2200000 [==============================] - 3825s - loss: 0.0798 - acc: 0.9773 - val_loss: 0.0629 - val_acc: 0.9820
Epoch 2/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9798Epoch 00001: val_loss improved from 0.06286 to 0.06128, saving model to models/weights/conv_net_22.hdf5
2200000/2200000 [==============================] - 3826s - loss: 0.0685 - acc: 0.9798 - val_loss: 0.0613 - val_acc: 0.9817
Epoch 3/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9801Epoch 00002: val_loss improved from 0.06128 to 0.05772, saving model to models/weights/conv_net_22.hdf5
2200000/2200000 [==============================] - 3825s - loss: 0.0663 - acc: 0.9801 - val_loss: 0.0577 - val_acc: 0.9824
Epoch 4/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9803Epoch 00003: val_loss improved from 0.05772 to 0.05687, saving model to models/weights/conv_net_22.hdf5
2200000/2200000 [==============================] - 3826s - loss: 0.0649 - acc: 0.9803 - val_loss: 0.0569 - val_acc: 0.9826
Epoch 5/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9805Epoch 00004: val_loss improved from 0.05687 to 0.05613, saving model to models/weights/conv_net_22.hdf5
2200000/2200000 [==============================] - 3826s - loss: 0.0640 - acc: 0.9805 - val_loss: 0.0561 - val_acc: 0.9828
Epoch 6/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9806Epoch 00005: val_loss improved from 0.05613 to 0.05561, saving model to models/weights/conv_net_22.hdf5
2200000/2200000 [==============================] - 3826s - loss: 0.0632 - acc: 0.9806 - val_loss: 0.0556 - val_acc: 0.9829
Epoch 7/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9807Epoch 00006: val_loss improved from 0.05561 to 0.05555, saving model to models/weights/conv_net_22.hdf5
2200000/2200000 [==============================] - 3825s - loss: 0.0626 - acc: 0.9807 - val_loss: 0.0555 - val_acc: 0.9830
Epoch 8/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9808Epoch 00007: val_loss did not improve
2200000/2200000 [==============================] - 3824s - loss: 0.0620 - acc: 0.9808 - val_loss: 0.0556 - val_acc: 0.9829
Epoch 9/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9809Epoch 00008: val_loss improved from 0.05555 to 0.05523, saving model to models/weights/conv_net_22.hdf5
2200000/2200000 [==============================] - 3825s - loss: 0.0616 - acc: 0.9809 - val_loss: 0.0552 - val_acc: 0.9828
Epoch 10/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9810Epoch 00009: val_loss did not improve
2200000/2200000 [==============================] - 3824s - loss: 0.0611 - acc: 0.9810 - val_loss: 0.0553 - val_acc: 0.9827
Epoch 11/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9811Epoch 00010: val_loss improved from 0.05523 to 0.05480, saving model to models/weights/conv_net_22.hdf5
2200000/2200000 [==============================] - 3825s - loss: 0.0606 - acc: 0.9811 - val_loss: 0.0548 - val_acc: 0.9830
Epoch 12/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9812Epoch 00011: val_loss did not improve
2200000/2200000 [==============================] - 3824s - loss: 0.0601 - acc: 0.9812 - val_loss: 0.0553 - val_acc: 0.9827
Epoch 13/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9813Epoch 00012: val_loss did not improve
2200000/2200000 [==============================] - 3823s - loss: 0.0597 - acc: 0.9813 - val_loss: 0.0552 - val_acc: 0.9829
Epoch 14/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9814Epoch 00013: val_loss did not improve
2200000/2200000 [==============================] - 3824s - loss: 0.0593 - acc: 0.9814 - val_loss: 0.0557 - val_acc: 0.9828
Epoch 15/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9815Epoch 00014: val_loss did not improve
