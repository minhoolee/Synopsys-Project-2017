
Retrieving train, validation, and test data
Building the model
Compiling model
Saving models in json and yaml format to models/json/conv_net_9.json and  models/yaml/conv_net_9.yaml
Saving weights to models/weights/conv_net_9.hdf5 and epoch logs to logs/half_set/conv_net_9.csv
Loading weights from models/weights/conv_net_9.hdf5 if it exists
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 128)      1664	   convolution1d_input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 998, 128)      0	   convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 128)      512	   activation_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)	 (None, 499, 128)      0	   batchnormalization_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 497, 256)      98560	   maxpooling1d_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)	 (None, 497, 256)      0	   convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 497, 256)      1024	   activation_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)	 (None, 248, 256)      0	   batchnormalization_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 244, 512)      655872	   maxpooling1d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)	 (None, 244, 512)      0	   convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 244, 512)      2048	   activation_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 240, 512)      1311232	   batchnormalization_3[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)	 (None, 240, 512)      0	   convolution1d_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)	 (None, 120, 512)      0	   activation_4[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)		 (None, 61440)	       0	   maxpooling1d_3[0][0]
____________________________________________________________________________________________________
dense_1 (Dense) 		 (None, 1024)	       62915584    flatten_1[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)	 (None, 1024)	       0	   dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 1024)	       4096	   activation_5[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)		 (None, 1024)	       0	   batchnormalization_4[0][0]
____________________________________________________________________________________________________
dense_2 (Dense) 		 (None, 919)	       941975	   dropout_1[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)	 (None, 919)	       0	   dense_2[0][0]
====================================================================================================
Total params: 65,932,567
Trainable params: 65,928,727
Non-trainable params: 3,840
____________________________________________________________________________________________________

Running at most 70 epochs
The date is 02/07/2017
The time is 06:54:21 PM

Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.07588--acc::0.9776Epoch 00000: val_loss improved from inf to 0.05914, saving model to models/weights/conv_net_9.hdf5
2200000/2200000 [==============================] - 6102s - loss: 0.0758 - acc: 0.9776 - val_loss: 0.0591 - val_acc: 0.9823
Epoch 2/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.06600--acc::0.9801Epoch 00001: val_loss improved from 0.05914 to 0.05786, saving model to models/weights/conv_net_9.hdf5
2200000/2200000 [==============================] - 6102s - loss: 0.0660 - acc: 0.9801 - val_loss: 0.0579 - val_acc: 0.9825
Epoch 3/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.06322--acc::0.9806Epoch 00002: val_loss improved from 0.05786 to 0.05718, saving model to models/weights/conv_net_9.hdf5
2200000/2200000 [==============================] - 6102s - loss: 0.0632 - acc: 0.9806 - val_loss: 0.0572 - val_acc: 0.9826
Epoch 4/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.06055--acc::0.9811Epoch 00003: val_loss improved from 0.05718 to 0.05621, saving model to models/weights/conv_net_9.hdf5
2200000/2200000 [==============================] - 6101s - loss: 0.0605 - acc: 0.9811 - val_loss: 0.0562 - val_acc: 0.9827
Epoch 5/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.05844--acc::0.9816Epoch 00004: val_loss did not improve
2200000/2200000 [==============================] - 6099s - loss: 0.0584 - acc: 0.9816 - val_loss: 0.0568 - val_acc: 0.9825
Epoch 6/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.05700--acc::0.9819Epoch 00005: val_loss did not improve
2200000/2200000 [==============================] - 6097s - loss: 0.0570 - acc: 0.9819 - val_loss: 0.0571 - val_acc: 0.9826
Epoch 7/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.05599--acc::0.9822Epoch 00006: val_loss did not improve
2200000/2200000 [==============================] - 6095s - loss: 0.0559 - acc: 0.9822 - val_loss: 0.0583 - val_acc: 0.9823
Epoch 8/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.05500--acc::0.9824Epoch 00007: val_loss did not improve
2200000/2200000 [==============================] - 6096s - loss: 0.0550 - acc: 0.9824 - val_loss: 0.0578 - val_acc: 0.9826
Epoch 9/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.05433--acc::0.9825Epoch 00008: val_loss did not improve
2200000/2200000 [==============================] - 6096s - loss: 0.0543 - acc: 0.9825 - val_loss: 0.0582 - val_acc: 0.9825
Epoch 10/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.05377--acc::0.9826Epoch 00009: val_loss did not improve
2200000/2200000 [==============================] - 6096s - loss: 0.0537 - acc: 0.9826 - val_loss: 0.0584 - val_acc: 0.9825
Epoch 00009: early stopping
455024/455024 [==============================] - 301s 0sss
[0.064020554842660865, 0.98106537337770794]
