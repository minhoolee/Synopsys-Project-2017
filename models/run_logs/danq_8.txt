Creating model from DanQ()
Building the model
Compiling model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 975, 320)      33600       convolution1d_input_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)    (None, 75, 320)       0           convolution1d_1[0][0]
____________________________________________________________________________________________________
bidirectional_1 (Bidirectional)  (None, 75, 640)       1640960     maxpooling1d_1[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 48000)         0           bidirectional_1[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 925)           44400925    flatten_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 925)           0           dense_1[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 919)           850994      activation_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 919)           0           dense_2[0][0]
====================================================================================================
Total params: 46,926,479
Trainable params: 46,926,479
Non-trainable params: 0
____________________________________________________________________________________________________
Saving models in json and yaml format to models/json/danq_8.json and  models/yaml/danq_8.yaml
Saving weights to models/weights/danq_8.hdf5 and epoch logs to models/csv/danq_8.csv
Retrieving train, validation, and test data

The date is 02/27/2017
The time is 02:15:50 AM

Run `tensorboard --logdir=models/run_logs/tensorboard` to open tensorboard at (default) 127.0.0.1:6006
Running at most 70 epochs
Epoch 1/70
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 9440 get requests, put_count=3959 evicted_count=1000 eviction_rate=0.252589 and unsatisfied allocation rate=0.69714
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
    100/2200000 [..............................] - ETA: 119507s - loss: 0.6967 - acc: 0.5007I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2858 get requests, put_count=6869 evicted_count=4000 eviction_rate=0.582326 and unsatisfied allocation rate=0
    300/2200000 [..............................] - ETA: 42083s - loss: 0.4431 - acc: 0.8047I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 805 get requests, put_count=1819 evicted_count=1000 eviction_rate=0.549753 and unsatisfied allocation rate=0
    400/2200000 [..............................] - ETA: 32403s - loss: 0.5671 - acc: 0.8243I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3387 get requests, put_count=8403 evicted_count=5000 eviction_rate=0.595026 and unsatisfied allocation rate=0
    600/2200000 [..............................] - ETA: 22716s - loss: 0.5336 - acc: 0.8448I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1645 get requests, put_count=3664 evicted_count=2000 eviction_rate=0.545852 and unsatisfied allocation rate=0
    700/2200000 [..............................] - ETA: 19951s - loss: 0.4891 - acc: 0.8572I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3724 get requests, put_count=9744 evicted_count=6000 eviction_rate=0.615764 and unsatisfied allocation rate=0.000268528
    900/2200000 [..............................] - ETA: 16267s - loss: 0.4096 - acc: 0.8824I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2438 get requests, put_count=5463 evicted_count=3000 eviction_rate=0.549149 and unsatisfied allocation rate=0
   1100/2200000 [..............................] - ETA: 13928s - loss: 0.3584 - acc: 0.8990I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 897 get requests, put_count=1927 evicted_count=1000 eviction_rate=0.518941 and unsatisfied allocation rate=0
   1200/2200000 [..............................] - ETA: 13050s - loss: 0.3389 - acc: 0.9048I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2588 get requests, put_count=6621 evicted_count=4000 eviction_rate=0.604138 and unsatisfied allocation rate=0
   1400/2200000 [..............................] - ETA: 11668s - loss: 0.3162 - acc: 0.9117I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1649 get requests, put_count=3689 evicted_count=2000 eviction_rate=0.542152 and unsatisfied allocation rate=0
   1600/2200000 [..............................] - ETA: 10627s - loss: 0.3196 - acc: 0.9158I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 12517 get requests, put_count=12514 evicted_count=6000 eviction_rate=0.479463 and unsatisfied allocation rate=0.483103
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 493 to 542
   1700/2200000 [..............................] - ETA: 10201s - loss: 0.3159 - acc: 0.9160I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2708 get requests, put_count=6762 evicted_count=4000 eviction_rate=0.591541 and unsatisfied allocation rate=0
   1900/2200000 [..............................] - ETA: 9482s - loss: 0.3030 - acc: 0.9200I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1680 get requests, put_count=3745 evicted_count=2000 eviction_rate=0.534045 and unsatisfied allocation rate=0
   2100/2200000 [..............................] - ETA: 8898s - loss: 0.2885 - acc: 0.9240I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 860 get requests, put_count=1939 evicted_count=1000 eviction_rate=0.51573 and unsatisfied allocation rate=0
   2200/2200000 [..............................] - ETA: 8647s - loss: 0.2835 - acc: 0.9253I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2936 get requests, put_count=8022 evicted_count=5000 eviction_rate=0.623286 and unsatisfied allocation rate=0.000340599
   2400/2200000 [..............................] - ETA: 8206s - loss: 0.2757 - acc: 0.9281I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2535 get requests, put_count=6640 evicted_count=4000 eviction_rate=0.60241 and unsatisfied allocation rate=0
   2600/2200000 [..............................] - ETA: 7833s - loss: 0.2641 - acc: 0.9319I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1938 get requests, put_count=5065 evicted_count=3000 eviction_rate=0.5923 and unsatisfied allocation rate=0
   2800/2200000 [..............................] - ETA: 7514s - loss: 0.2522 - acc: 0.9353I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1908 get requests, put_count=5062 evicted_count=3000 eviction_rate=0.592651 and unsatisfied allocation rate=0
   3000/2200000 [..............................] - ETA: 7236s - loss: 0.2475 - acc: 0.9360I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1530 get requests, put_count=4716 evicted_count=3000 eviction_rate=0.636132 and unsatisfied allocation rate=0
   3300/2200000 [..............................] - ETA: 6883s - loss: 0.2347 - acc: 0.9388I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 991 get requests, put_count=2238 evicted_count=1000 eviction_rate=0.446828 and unsatisfied allocation rate=0
   3600/2200000 [..............................] - ETA: 6589s - loss: 0.2238 - acc: 0.9419I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 12582 get requests, put_count=12638 evicted_count=3000 eviction_rate=0.237379 and unsatisfied allocation rate=0.257749
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 3296 to 3625
   4000/2200000 [..............................] - ETA: 6265s - loss: 0.2118 - acc: 0.9453I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 436 get requests, put_count=1918 evicted_count=1000 eviction_rate=0.521376 and unsatisfied allocation rate=0
2199900/2200000 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9791Epoch 00000: val_loss improved from inf to 0.06767, saving model to models/weights/danq_8.hdf5
2200000/2200000 [==============================] - 3398s - loss: 0.0776 - acc: 0.9791 - val_loss: 0.0677 - val_acc: 0.9813
Epoch 2/70
2199900/2200000 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9792Epoch 00001: val_loss improved from 0.06767 to 0.06697, saving model to models/weights/danq_8.hdf5
2200000/2200000 [==============================] - 3395s - loss: 0.0753 - acc: 0.9792 - val_loss: 0.0670 - val_acc: 0.9816
Epoch 3/70
2199900/2200000 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9793Epoch 00002: val_loss improved from 0.06697 to 0.06688, saving model to models/weights/danq_8.hdf5
2200000/2200000 [==============================] - 3395s - loss: 0.0754 - acc: 0.9793 - val_loss: 0.0669 - val_acc: 0.9814
Epoch 4/70
2199900/2200000 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9793Epoch 00003: val_loss did not improve
2200000/2200000 [==============================] - 3364s - loss: 0.0756 - acc: 0.9793 - val_loss: 0.0675 - val_acc: 0.9813
Epoch 5/70
2199900/2200000 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9793Epoch 00004: val_loss did not improve
2200000/2200000 [==============================] - 3361s - loss: 0.0752 - acc: 0.9793 - val_loss: 0.0670 - val_acc: 0.9812
Epoch 6/70
2199900/2200000 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9793Epoch 00005: val_loss did not improve

Epoch 00005: reducing learning rate to 0.00020000000949949026.
2200000/2200000 [==============================] - 3348s - loss: 0.0748 - acc: 0.9793 - val_loss: 0.0673 - val_acc: 0.9813
Epoch 7/70
 866400/2200000 [==========>...................] - ETA: 2030s - loss: 0.0753 - acc: 0.97as^A
 877100/2200000 [==========>...................] - ETA: 2013s - loss: 0.0753 - acc: 0.as  ^A
2199900/2200000 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9794Epoch 00006: val_loss improved from 0.06688 to 0.06631, saving model to models/weights/danq_8.hdf5
2200000/2200000 [==============================] - 3346s - loss: 0.0739 - acc: 0.9794 - val_loss: 0.0663 - val_acc: 0.9815
