2017-03-16 00:42:40,088 src.models.keras_model_utils INFO     Creating model from conv_net()
2017-03-16 00:42:40,088 src.models.create_models INFO     Building the model
2017-03-16 00:42:42,284 src.models.create_models INFO     Compiling model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
input_1 (InputLayer)             (None, 1000, 4)       0
____________________________________________________________________________________________________
convolution1d_1 (Convolution1D)  (None, 998, 64)       832         input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 998, 64)       0           convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 64)       256         activation_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)    (None, 499, 64)       0           batchnormalization_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 497, 64)       12352       maxpooling1d_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 497, 64)       0           convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 497, 64)       256         activation_2[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 497, 64)       0           batchnormalization_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)    (None, 248, 64)       0           dropout_1[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 246, 128)      24704       maxpooling1d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 246, 128)      0           convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 246, 128)      512         activation_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 244, 128)      49280       batchnormalization_3[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)        (None, 244, 128)      0           convolution1d_4[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 244, 128)      512         activation_4[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 244, 128)      0           batchnormalization_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)    (None, 122, 128)      0           dropout_2[0][0]
____________________________________________________________________________________________________
convolution1d_5 (Convolution1D)  (None, 120, 256)      98560       maxpooling1d_3[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)        (None, 120, 256)      0           convolution1d_5[0][0]
____________________________________________________________________________________________________
batchnormalization_5 (BatchNorma (None, 120, 256)      1024        activation_5[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 120, 256)      0           batchnormalization_5[0][0]
____________________________________________________________________________________________________
convolution1d_6 (Convolution1D)  (None, 118, 256)      196864      dropout_3[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)        (None, 118, 256)      0           convolution1d_6[0][0]
____________________________________________________________________________________________________
batchnormalization_6 (BatchNorma (None, 118, 256)      1024        activation_6[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 118, 256)      0           batchnormalization_6[0][0]
____________________________________________________________________________________________________
maxpooling1d_4 (MaxPooling1D)    (None, 59, 256)       0           dropout_4[0][0]
____________________________________________________________________________________________________
bidirectional_1 (Bidirectional)  (None, 59, 512)       787968      maxpooling1d_4[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 30208)         0           bidirectional_1[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1024)          30934016    flatten_1[0][0]
____________________________________________________________________________________________________
activation_7 (Activation)        (None, 1024)          0           dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_7 (BatchNorma (None, 1024)          4096        activation_7[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 1024)          0           batchnormalization_7[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 919)           941975      dropout_5[0][0]
____________________________________________________________________________________________________
activation_8 (Activation)        (None, 919)           0           dense_2[0][0]
====================================================================================================
Total params: 33,054,231
Trainable params: 33,050,391
Non-trainable params: 3,840
____________________________________________________________________________________________________
2017-03-16 00:42:43,597 __main__     INFO     Retrieving train data...
2017-03-16 00:43:52,568 __main__     INFO     Retrieving validation data...
2017-03-16 00:43:52,659 __main__     INFO     Saving model to file system...
2017-03-16 00:43:52,659 src.models.keras_model_utils INFO     Saving models/json/conv_net_large_2.json to models/json/conv_net_large_2.json.old
2017-03-16 00:43:52,659 src.models.keras_model_utils INFO     Saving model to models/json/conv_net_large_2.json
2017-03-16 00:43:52,661 src.models.keras_model_utils INFO     Saving models/yaml/conv_net_large_2.yaml to models/yaml/conv_net_large_2.yaml.old
2017-03-16 00:43:52,661 src.models.keras_model_utils INFO     Saving model to models/yaml/conv_net_large_2.yaml
2017-03-16 00:43:52,688 __main__     INFO     Loading model weights...
2017-03-16 00:43:52,688 __main__     INFO     The date is 03/16/2017
2017-03-16 00:43:52,688 __main__     INFO     The time is 12:43:52 AM

2017-03-16 00:43:52,688 __main__     INFO     Training model...
2017-03-16 00:43:52,688 src.models.keras_model_utils INFO     Running at most 70 epochs
2017-03-16 00:43:52,688 src.models.keras_model_utils INFO     Saving weights to models/weights/conv_net_large_2.hdf5 and epoch logs to models/csv/conv_net_large_2.csv
Train on 4400000 samples, validate on 8000 samples
Epoch 1/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9780Epoch 00000: val_loss improved from inf to 0.06098, saving model to models/weights/conv_net_large_2.hdf5
4400000/4400000 [==============================] - 6266s - loss: 0.0764 - acc: 0.9780 - val_loss: 0.0610 - val_acc: 0.9820
Epoch 2/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9798Epoch 00001: val_loss improved from 0.06098 to 0.05852, saving model to models/weights/conv_net_large_2.hdf5
4400000/4400000 [==============================] - 6254s - loss: 0.0691 - acc: 0.9798 - val_loss: 0.0585 - val_acc: 0.9827
Epoch 3/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9800Epoch 00002: val_loss improved from 0.05852 to 0.05809, saving model to models/weights/conv_net_large_2.hdf5
4400000/4400000 [==============================] - 6246s - loss: 0.0678 - acc: 0.9800 - val_loss: 0.0581 - val_acc: 0.9827
Epoch 4/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9801Epoch 00003: val_loss improved from 0.05809 to 0.05738, saving model to models/weights/conv_net_large_2.hdf5
4400000/4400000 [==============================] - 6246s - loss: 0.0672 - acc: 0.9801 - val_loss: 0.0574 - val_acc: 0.9827
Epoch 5/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9801Epoch 00004: val_loss improved from 0.05738 to 0.05723, saving model to models/weights/conv_net_large_2.hdf5
4400000/4400000 [==============================] - 6246s - loss: 0.0667 - acc: 0.9801 - val_loss: 0.0572 - val_acc: 0.9828
Epoch 6/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9802Epoch 00005: val_loss improved from 0.05723 to 0.05695, saving model to models/weights/conv_net_large_2.hdf5
4400000/4400000 [==============================] - 6246s - loss: 0.0663 - acc: 0.9802 - val_loss: 0.0569 - val_acc: 0.9828
Epoch 7/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9802Epoch 00006: val_loss did not improve
4400000/4400000 [==============================] - 6245s - loss: 0.0660 - acc: 0.9802 - val_loss: 0.0577 - val_acc: 0.9827
Epoch 8/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9802Epoch 00007: val_loss improved from 0.05695 to 0.05662, saving model to models/weights/conv_net_large_2.hdf5
4400000/4400000 [==============================] - 6246s - loss: 0.0658 - acc: 0.9802 - val_loss: 0.0566 - val_acc: 0.9828
Epoch 9/70
3941200/4400000 [=========================>....] - ETA: 653s - loss: 0.0656 - acc: 0.9803 ^[
3942400/4400000 [=========================>....] - ETA: 651s - loss: 0.0656 - acc: 0.9803
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9803Epoch 00008: val_loss improved from 0.05662 to 0.05622, saving model to models/weights/conv_net_large_2.hdf5
4400000/4400000 [==============================] - 6274s - loss: 0.0656 - acc: 0.9803 - val_loss: 0.0562 - val_acc: 0.9829
Epoch 10/70
4399600/4400000 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9803Epoch 00009: val_loss did not improve
4400000/4400000 [==============================] - 6298s - loss: 0.0655 - acc: 0.9803 - val_loss: 0.0567 - val_acc: 0.9827
