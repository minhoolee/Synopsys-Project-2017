Creating model from DanQ()
Building the model
Compiling model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 975, 320)      33600       convolution1d_input_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)    (None, 75, 320)       0           convolution1d_1[0][0]
____________________________________________________________________________________________________
bidirectional_1 (Bidirectional)  (None, 75, 640)       1640960     maxpooling1d_1[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 48000)         0           bidirectional_1[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 925)           44400925    flatten_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 925)           0           dense_1[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 919)           850994      activation_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 919)           0           dense_2[0][0]
====================================================================================================
Total params: 46,926,479
Trainable params: 46,926,479
Non-trainable params: 0
____________________________________________________________________________________________________
Saving models in json and yaml format to models/json/danq_12.json and  models/yaml/danq_12.yaml
Saving weights to models/weights/danq_12.hdf5 and epoch logs to models/csv/danq_12.csv
Retrieving train, validation, and test data

The date is 02/28/2017
The time is 01:11:40 PM

Running at most 70 epochs
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9790Epoch 00000: val_loss improved from inf to 0.06382, saving model to models/weights/danq_12.hdf5
2200000/2200000 [==============================] - 3841s - loss: 0.0781 - acc: 0.9790 - val_loss: 0.0638 - val_acc: 0.9818
Epoch 2/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9797Epoch 00001: val_loss improved from 0.06382 to 0.06293, saving model to models/weights/danq_12.hdf5
2200000/2200000 [==============================] - 3837s - loss: 0.0716 - acc: 0.9797 - val_loss: 0.0629 - val_acc: 0.9819
Epoch 3/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9798Epoch 00002: val_loss improved from 0.06293 to 0.06222, saving model to models/weights/danq_12.hdf5
2200000/2200000 [==============================] - 3842s - loss: 0.0705 - acc: 0.9798 - val_loss: 0.0622 - val_acc: 0.9818
Epoch 4/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9799Epoch 00003: val_loss did not improve
2200000/2200000 [==============================] - 3838s - loss: 0.0700 - acc: 0.9799 - val_loss: 0.0622 - val_acc: 0.9818
Epoch 5/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9799Epoch 00004: val_loss did not improve
2200000/2200000 [==============================] - 3838s - loss: 0.0698 - acc: 0.9799 - val_loss: 0.0625 - val_acc: 0.9819
Epoch 6/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9799Epoch 00005: val_loss did not improve
2200000/2200000 [==============================] - 3836s - loss: 0.0697 - acc: 0.9799 - val_loss: 0.0624 - val_acc: 0.9818
Epoch 7/70
2199600/2200000 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9799Epoch 00006: val_loss did not improve
2200000/2200000 [==============================] - 3837s - loss: 0.0697 - acc: 0.9799 - val_loss: 0.0627 - val_acc: 0.9817
