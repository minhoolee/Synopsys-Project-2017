
Creating model from conv_net()
Building the model
Compiling model
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 64)       832	   convolution1d_input_1[0][0]
____________________________________________________________________________________________________
prelu_1 (PReLU) 		 (None, 998, 64)       63872	   convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 64)       256	   prelu_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 996, 64)       12352	   batchnormalization_1[0][0]
____________________________________________________________________________________________________
prelu_2 (PReLU) 		 (None, 996, 64)       63744	   convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 996, 64)       256	   prelu_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 994, 128)      24704	   batchnormalization_2[0][0]
____________________________________________________________________________________________________
prelu_3 (PReLU) 		 (None, 994, 128)      127232	   convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 994, 128)      512	   prelu_3[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)		 (None, 994, 128)      0	   batchnormalization_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 496, 128)      49280	   dropout_1[0][0]
____________________________________________________________________________________________________
prelu_4 (PReLU) 		 (None, 496, 128)      63488	   convolution1d_4[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 496, 128)      512	   prelu_4[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)		 (None, 496, 128)      0	   batchnormalization_4[0][0]
____________________________________________________________________________________________________
convolution1d_5 (Convolution1D)  (None, 246, 256)      164096	   dropout_2[0][0]
____________________________________________________________________________________________________
prelu_5 (PReLU) 		 (None, 246, 256)      62976	   convolution1d_5[0][0]
____________________________________________________________________________________________________
batchnormalization_5 (BatchNorma (None, 246, 256)      1024	   prelu_5[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)		 (None, 246, 256)      0	   batchnormalization_5[0][0]
____________________________________________________________________________________________________
convolution1d_6 (Convolution1D)  (None, 121, 256)      327936	   dropout_3[0][0]
____________________________________________________________________________________________________
prelu_6 (PReLU) 		 (None, 121, 256)      30976	   convolution1d_6[0][0]
____________________________________________________________________________________________________
batchnormalization_6 (BatchNorma (None, 121, 256)      1024	   prelu_6[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)		 (None, 121, 256)      0	   batchnormalization_6[0][0]
____________________________________________________________________________________________________
convolution1d_7 (Convolution1D)  (None, 1, 919)        28467863    dropout_4[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 1, 919)        0	   convolution1d_7[0][0]
====================================================================================================
Total params: 29,462,935
Trainable params: 29,461,143
Non-trainable params: 1,792
____________________________________________________________________________________________________
Saving models in json and yaml format to models/json/conv_net_24.json and  models/yaml/conv_net_24.yaml
Saving weights to models/weights/conv_net_24.hdf5 and epoch logs to models/csv/conv_net_24.csv
Retrieving train, validation, and test data

The date is 02/23/2017
The time is 09:03:44 AM

Loading weights from models/weights/conv_net_24.hdf5 if it exists
Running at most 70 epochs

Creating model from conv_net()
Building the model

Creating model from conv_net()
Building the model

Creating model from conv_net()
Building the model
Compiling model
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 64)       832	   convolution1d_input_1[0][0]
____________________________________________________________________________________________________
prelu_1 (PReLU) 		 (None, 998, 64)       63872	   convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 64)       256	   prelu_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 996, 64)       12352	   batchnormalization_1[0][0]
____________________________________________________________________________________________________
prelu_2 (PReLU) 		 (None, 996, 64)       63744	   convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 996, 64)       256	   prelu_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 497, 128)      24704	   batchnormalization_2[0][0]
____________________________________________________________________________________________________
prelu_3 (PReLU) 		 (None, 497, 128)      63616	   convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 497, 128)      512	   prelu_3[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)		 (None, 497, 128)      0	   batchnormalization_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 248, 128)      49280	   dropout_1[0][0]
____________________________________________________________________________________________________
prelu_4 (PReLU) 		 (None, 248, 128)      31744	   convolution1d_4[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 248, 128)      512	   prelu_4[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)		 (None, 248, 128)      0	   batchnormalization_4[0][0]
____________________________________________________________________________________________________
convolution1d_5 (Convolution1D)  (None, 122, 256)      164096	   dropout_2[0][0]
____________________________________________________________________________________________________
prelu_5 (PReLU) 		 (None, 122, 256)      31232	   convolution1d_5[0][0]
____________________________________________________________________________________________________
batchnormalization_5 (BatchNorma (None, 122, 256)      1024	   prelu_5[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)		 (None, 122, 256)      0	   batchnormalization_5[0][0]
____________________________________________________________________________________________________
convolution1d_6 (Convolution1D)  (None, 59, 256)       327936	   dropout_3[0][0]
____________________________________________________________________________________________________
prelu_6 (PReLU) 		 (None, 59, 256)       15104	   convolution1d_6[0][0]
____________________________________________________________________________________________________
batchnormalization_6 (BatchNorma (None, 59, 256)       1024	   prelu_6[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)		 (None, 15104)	       0	   batchnormalization_6[0][0]
____________________________________________________________________________________________________
dense_1 (Dense) 		 (None, 1024)	       15467520    flatten_1[0][0]
____________________________________________________________________________________________________
prelu_7 (PReLU) 		 (None, 1024)	       1024	   dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_7 (BatchNorma (None, 1024)	       4096	   prelu_7[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)		 (None, 1024)	       0	   batchnormalization_7[0][0]
____________________________________________________________________________________________________
dense_2 (Dense) 		 (None, 919)	       941975	   dropout_4[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 919)	       0	   dense_2[0][0]
====================================================================================================
Total params: 17,266,711
Trainable params: 17,262,871
Non-trainable params: 3,840
____________________________________________________________________________________________________
Saving models in json and yaml format to models/json/conv_net_24.json and  models/yaml/conv_net_24.yaml
Saving weights to models/weights/conv_net_24.hdf5 and epoch logs to models/csv/conv_net_24.csv
Saving models/json/conv_net_24.json to models/json/conv_net_24.json.old
Saving models/yaml/conv_net_24.yaml to models/yaml/conv_net_24.yaml.old
Retrieving train, validation, and test data

The date is 02/23/2017
The time is 11:24:46 AM

Loading weights from models/weights/conv_net_24.hdf5 if it exists
Saving models/csv/conv_net_24.csv to models/csv/conv_net_24.csv.old
Running at most 70 epochs
Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.08944--acc::0.9753Epoch 00000: val_loss improved from inf to 0.06722, saving model to models/weights/conv_net_24.hdf5
2200000/2200000 [==============================] - 2392s - loss: 0.0894 - acc: 0.9753 - val_loss: 0.0672 - val_acc: 0.9816
Epoch 2/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.07211--acc::0.9794Epoch 00001: val_loss improved from 0.06722 to 0.06165, saving model to models/weights/conv_net_24.hdf5
2200000/2200000 [==============================] - 2392s - loss: 0.0721 - acc: 0.9794 - val_loss: 0.0617 - val_acc: 0.9824
Epoch 3/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.07000--acc::0.9797Epoch 00002: val_loss improved from 0.06165 to 0.06075, saving model to models/weights/conv_net_24.hdf5
2200000/2200000 [==============================] - 2390s - loss: 0.0700 - acc: 0.9797 - val_loss: 0.0608 - val_acc: 0.9825
Epoch 4/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06833--acc::0.9800Epoch 00003: val_loss improved from 0.06075 to 0.05966, saving model to models/weights/conv_net_24.hdf5
2200000/2200000 [==============================] - 2392s - loss: 0.0683 - acc: 0.9800 - val_loss: 0.0597 - val_acc: 0.9825
Epoch 5/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06700--acc::0.9801Epoch 00004: val_loss improved from 0.05966 to 0.05831, saving model to models/weights/conv_net_24.hdf5
2200000/2200000 [==============================] - 2393s - loss: 0.0670 - acc: 0.9801 - val_loss: 0.0583 - val_acc: 0.9827
Epoch 6/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06600--acc::0.9803Epoch 00005: val_loss improved from 0.05831 to 0.05750, saving model to models/weights/conv_net_24.hdf5
2200000/2200000 [==============================] - 2391s - loss: 0.0660 - acc: 0.9803 - val_loss: 0.0575 - val_acc: 0.9828
Epoch 7/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06522--acc::0.9804Epoch 00006: val_loss improved from 0.05750 to 0.05713, saving model to models/weights/conv_net_24.hdf5
2200000/2200000 [==============================] - 2389s - loss: 0.0652 - acc: 0.9804 - val_loss: 0.0571 - val_acc: 0.9829
Epoch 8/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06455--acc::0.9805Epoch 00007: val_loss improved from 0.05713 to 0.05668, saving model to models/weights/conv_net_24.hdf5
2200000/2200000 [==============================] - 2388s - loss: 0.0645 - acc: 0.9805 - val_loss: 0.0567 - val_acc: 0.9828
Epoch 9/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06400--acc::0.9806Epoch 00008: val_loss did not improve
2200000/2200000 [==============================] - 2389s - loss: 0.0640 - acc: 0.9806 - val_loss: 0.0567 - val_acc: 0.9828
Epoch 10/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06366--acc::0.9807Epoch 00009: val_loss improved from 0.05668 to 0.05620, saving model to models/weights/conv_net_24.hdf5
2200000/2200000 [==============================] - 2389s - loss: 0.0636 - acc: 0.9807 - val_loss: 0.0562 - val_acc: 0.9829
Epoch 11/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06311--acc::0.9807Epoch 00010: val_loss did not improve
2200000/2200000 [==============================] - 2388s - loss: 0.0631 - acc: 0.9807 - val_loss: 0.0567 - val_acc: 0.9829
Epoch 12/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06277--acc::0.9808Epoch 00011: val_loss did not improve
2200000/2200000 [==============================] - 2388s - loss: 0.0627 - acc: 0.9808 - val_loss: 0.0562 - val_acc: 0.9828
Epoch 13/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06244--acc::0.9809Epoch 00012: val_loss did not improve
2200000/2200000 [==============================] - 2388s - loss: 0.0624 - acc: 0.9809 - val_loss: 0.0563 - val_acc: 0.9829
Epoch 14/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06200--acc::0.9810Epoch 00013: val_loss did not improve
2200000/2200000 [==============================] - 2388s - loss: 0.0620 - acc: 0.9810 - val_loss: 0.0566 - val_acc: 0.9828
Epoch 15/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06177--acc::0.9811Epoch 00014: val_loss did not improve
2200000/2200000 [==============================] - 2388s - loss: 0.0617 - acc: 0.9811 - val_loss: 0.0565 - val_acc: 0.9828
Epoch 16/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06133--acc::0.9811Epoch 00015: val_loss did not improve
2200000/2200000 [==============================] - 2388s - loss: 0.0613 - acc: 0.9811 - val_loss: 0.0567 - val_acc: 0.9828
Epoch 00015: early stopping
455008/455024 [============================>.] - ETA: 0s[0.061266966373568793, 0.98129786181967149]
