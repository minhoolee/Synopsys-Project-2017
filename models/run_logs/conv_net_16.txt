Creating model from conv_net()
Building the model
Compiling model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 64)       832         convolution1d_input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 998, 64)       0           convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 64)       256         activation_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 996, 64)       12352       batchnormalization_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 996, 64)       0           convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 996, 64)       256         activation_2[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)              (None, 996, 64)       0           batchnormalization_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)    (None, 498, 64)       0           dropout_1[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 496, 128)      24704       maxpooling1d_1[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)        (None, 496, 128)      0           convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 496, 128)      512         activation_3[0][0]
____________________________________________________________________________________________________
dropout_2 (Dropout)              (None, 496, 128)      0           batchnormalization_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 494, 128)      49280       dropout_2[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)        (None, 494, 128)      0           convolution1d_4[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 494, 128)      512         activation_4[0][0]
____________________________________________________________________________________________________
dropout_3 (Dropout)              (None, 494, 128)      0           batchnormalization_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)    (None, 247, 128)      0           dropout_3[0][0]
____________________________________________________________________________________________________
convolution1d_5 (Convolution1D)  (None, 245, 256)      98560       maxpooling1d_2[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)        (None, 245, 256)      0           convolution1d_5[0][0]
____________________________________________________________________________________________________
batchnormalization_5 (BatchNorma (None, 245, 256)      1024        activation_5[0][0]
____________________________________________________________________________________________________
dropout_4 (Dropout)              (None, 245, 256)      0           batchnormalization_5[0][0]
____________________________________________________________________________________________________
convolution1d_6 (Convolution1D)  (None, 243, 256)      196864      dropout_4[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)        (None, 243, 256)      0           convolution1d_6[0][0]
____________________________________________________________________________________________________
batchnormalization_6 (BatchNorma (None, 243, 256)      1024        activation_6[0][0]
____________________________________________________________________________________________________
dropout_5 (Dropout)              (None, 243, 256)      0           batchnormalization_6[0][0]
____________________________________________________________________________________________________
convolution1d_7 (Convolution1D)  (None, 241, 256)      196864      dropout_5[0][0]
____________________________________________________________________________________________________
activation_7 (Activation)        (None, 241, 256)      0           convolution1d_7[0][0]
____________________________________________________________________________________________________
batchnormalization_7 (BatchNorma (None, 241, 256)      1024        activation_7[0][0]
____________________________________________________________________________________________________
dropout_6 (Dropout)              (None, 241, 256)      0           batchnormalization_7[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)    (None, 120, 256)      0           dropout_6[0][0]
____________________________________________________________________________________________________
convolution1d_8 (Convolution1D)  (None, 118, 512)      393728      maxpooling1d_3[0][0]
____________________________________________________________________________________________________
activation_8 (Activation)        (None, 118, 512)      0           convolution1d_8[0][0]
____________________________________________________________________________________________________
batchnormalization_8 (BatchNorma (None, 118, 512)      2048        activation_8[0][0]
____________________________________________________________________________________________________
dropout_7 (Dropout)              (None, 118, 512)      0           batchnormalization_8[0][0]
____________________________________________________________________________________________________
convolution1d_9 (Convolution1D)  (None, 116, 512)      786944      dropout_7[0][0]
____________________________________________________________________________________________________
activation_9 (Activation)        (None, 116, 512)      0           convolution1d_9[0][0]
____________________________________________________________________________________________________
batchnormalization_9 (BatchNorma (None, 116, 512)      2048        activation_9[0][0]
____________________________________________________________________________________________________
dropout_8 (Dropout)              (None, 116, 512)      0           batchnormalization_9[0][0]
____________________________________________________________________________________________________
convolution1d_10 (Convolution1D) (None, 114, 512)      786944      dropout_8[0][0]
____________________________________________________________________________________________________
activation_10 (Activation)       (None, 114, 512)      0           convolution1d_10[0][0]
____________________________________________________________________________________________________
batchnormalization_10 (BatchNorm (None, 114, 512)      2048        activation_10[0][0]
____________________________________________________________________________________________________
dropout_9 (Dropout)              (None, 114, 512)      0           batchnormalization_10[0][0]
____________________________________________________________________________________________________
maxpooling1d_4 (MaxPooling1D)    (None, 57, 512)       0           dropout_9[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 29184)         0           maxpooling1d_4[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 1024)          29885440    flatten_1[0][0]
____________________________________________________________________________________________________
activation_11 (Activation)       (None, 1024)          0           dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_11 (BatchNorm (None, 1024)          4096        activation_11[0][0]
____________________________________________________________________________________________________
dropout_10 (Dropout)             (None, 1024)          0           batchnormalization_11[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 919)           941975      dropout_10[0][0]
____________________________________________________________________________________________________
activation_12 (Activation)       (None, 919)           0           dense_2[0][0]
====================================================================================================
Total params: 33,389,335
Trainable params: 33,381,911
Non-trainable params: 7,424
____________________________________________________________________________________________________
Saving models in json and yaml format to models/json/conv_net_16.json and  models/yaml/conv_net_16.yaml
Saving weights to models/weights/conv_net_16.hdf5 and epoch logs to models/csv/conv_net_16.csv
Saving models/json/conv_net_16.json to models/json/conv_net_16.json.old
Saving models/yaml/conv_net_16.yaml to models/yaml/conv_net_16.yaml.old
Retrieving train, validation, and test data

The date is 02/18/2017
The time is 09:09:39 AM

Loading weights from models/weights/conv_net_16.hdf5 if it exists
Saving models/csv/conv_net_16.csv to models/csv/conv_net_16.csv.old
Running at most 70 epochs
Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 1s - loss: 0.0905 - acc: 0.9765Epoch 00000: val_loss improved from inf to 0.10990, saving model to models/weights/conv_net_16.hdf5
2200000/2200000 [==============================] - 7343s - loss: 0.0905 - acc: 0.9765 - val_loss: 0.1099 - val_acc: 0.9785
Epoch 2/70
2199600/2200000 [============================>.] - ETA: 1s - loss: 0.0726 - acc: 0.9793Epoch 00001: val_loss improved from 0.10990 to 0.06511, saving model to models/weights/conv_net_16.hdf5
2200000/2200000 [==============================] - 7340s - loss: 0.0726 - acc: 0.9793 - val_loss: 0.0651 - val_acc: 0.9817
Epoch 3/70
2199600/2200000 [============================>.] - ETA: 1s - loss: 0.0700 - acc: 0.9797Epoch 00002: val_loss improved from 0.06511 to 0.06155, saving model to models/weights/conv_net_16.hdf5
2200000/2200000 [==============================] - 7338s - loss: 0.0700 - acc: 0.9797 - val_loss: 0.0616 - val_acc: 0.9822
Epoch 4/70
2199600/2200000 [============================>.] - ETA: 1s - loss: 0.0679 - acc: 0.9799Epoch 00003: val_loss did not improve
2200000/2200000 [==============================] - 7337s - loss: 0.0679 - acc: 0.9799 - val_loss: 0.0648 - val_acc: 0.9821
Epoch 5/70
2199600/2200000 [============================>.] - ETA: 1s - loss: 0.0668 - acc: 0.9801Epoch 00004: val_loss improved from 0.06155 to 0.06069, saving model to models/weights/conv_net_16.hdf5
2200000/2200000 [==============================] - 7337s - loss: 0.0668 - acc: 0.9801 - val_loss: 0.0607 - val_acc: 0.9825
Epoch 6/70
2199600/2200000 [============================>.] - ETA: 1s - loss: 0.0659 - acc: 0.9802Epoch 00005: val_loss did not improve
2200000/2200000 [==============================] - 7339s - loss: 0.0659 - acc: 0.9802 - val_loss: 0.0658 - val_acc: 0.9820
Epoch 7/70
2199600/2200000 [============================>.] - ETA: 1s - loss: 0.0653 - acc: 0.9803Epoch 00006: val_loss did not improve
2200000/2200000 [==============================] - 7338s - loss: 0.0653 - acc: 0.9803 - val_loss: 0.0683 - val_acc: 0.9818
455024/455024 [==============================] - 299s
[0.066044405574302106, 0.98108348319029071]
