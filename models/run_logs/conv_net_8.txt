
Retrieving train, validation, and test data
Building the model
Compiling model
Saving models in json and yaml format to models/json/conv_net_8.json and  models/yaml/conv_net_8.yaml
Saving weights to models/weights/conv_net_8.hdf5 and epoch logs to logs/half_set/conv_net_8.csv
Saving models/json/conv_net_8.json to models/json/conv_net_8.json.old
Saving models/yaml/conv_net_8.yaml to models/yaml/conv_net_8.yaml.old
Loading weights from models/weights/conv_net_8.hdf5 if it exists
Saving logs/half_set/conv_net_8.csv to logs/half_set/conv_net_8.csv.old

Running at most 70 epochs
The date is 02/06/2017
The time is 06:35:07 PM

[<keras.callbacks.ModelCheckpoint object at 0x7fcff5125da0>, <keras.callbacks.EarlyStopping object at 0x7fcff50f6c18>, <keras.callbacks.CSVLogger object at 0x7fcff508d128>, <keras.callbacks.TensorBoard object at 0x7fcff508dcc0>]
Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.07333--acc::0.9791Epoch 00000: val_loss improved from inf to 0.06010, saving model to models/weights/conv_net_8.hdf5

Retrieving train, validation, and test data
Building the model
Compiling model
Saving models in json and yaml format to models/json/conv_net_8.json and  models/yaml/conv_net_8.yaml
Saving weights to models/weights/conv_net_8.hdf5 and epoch logs to logs/half_set/conv_net_8.csv
Saving models/json/conv_net_8.json to models/json/conv_net_8.json.old
Saving models/yaml/conv_net_8.yaml to models/yaml/conv_net_8.yaml.old
Loading weights from models/weights/conv_net_8.hdf5 if it exists
Saving models/weights/conv_net_8.hdf5 to models/weights/conv_net_8.hdf5.old
Saving logs/half_set/conv_net_8.csv to logs/half_set/conv_net_8.csv.old
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 128)      1664	   convolution1d_input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 998, 128)      0	   convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 128)      512	   activation_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)	 (None, 499, 128)      0	   batchnormalization_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 497, 256)      98560	   maxpooling1d_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)	 (None, 497, 256)      0	   convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 497, 256)      1024	   activation_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)	 (None, 248, 256)      0	   batchnormalization_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 244, 512)      655872	   maxpooling1d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)	 (None, 244, 512)      0	   convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 244, 512)      2048	   activation_3[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)	 (None, 122, 512)      0	   batchnormalization_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 118, 512)      1311232	   maxpooling1d_3[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)	 (None, 118, 512)      0	   convolution1d_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_4 (MaxPooling1D)	 (None, 59, 512)       0	   activation_4[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)		 (None, 30208)	       0	   maxpooling1d_4[0][0]
____________________________________________________________________________________________________
dense_1 (Dense) 		 (None, 1024)	       30934016    flatten_1[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)	 (None, 1024)	       0	   dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 1024)	       4096	   activation_5[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)		 (None, 1024)	       0	   batchnormalization_4[0][0]
____________________________________________________________________________________________________
dense_2 (Dense) 		 (None, 919)	       941975	   dropout_1[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)	 (None, 919)	       0	   dense_2[0][0]
====================================================================================================
Total params: 33,950,999
Trainable params: 33,947,159
Non-trainable params: 3,840
____________________________________________________________________________________________________

Running at most 70 epochs
The date is 02/06/2017
The time is 07:41:08 PM

Run `tensorboard --logdir=` to open tensorboard at (default) 127.0.0.1:6006
Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06922--acc::0.9797Epoch 00000: val_loss improved from inf to 0.05860, saving model to models/weights/conv_net_8.hdf5

Retrieving train, validation, and test data
Building the model
Compiling model
Saving models in json and yaml format to models/json/conv_net_8.json and  models/yaml/conv_net_8.yaml
Saving weights to models/weights/conv_net_8.hdf5 and epoch logs to logs/half_set/conv_net_8.csv
Saving models/json/conv_net_8.json to models/json/conv_net_8.json.old
Saving models/yaml/conv_net_8.yaml to models/yaml/conv_net_8.yaml.old
Loading weights from models/weights/conv_net_8.hdf5 if it exists
Saving models/weights/conv_net_8.hdf5 to models/weights/conv_net_8.hdf5.old
Saving logs/half_set/conv_net_8.csv to logs/half_set/conv_net_8.csv.old
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 128)      1664	   convolution1d_input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 998, 128)      0	   convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 128)      512	   activation_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)	 (None, 499, 128)      0	   batchnormalization_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 497, 256)      98560	   maxpooling1d_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)	 (None, 497, 256)      0	   convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 497, 256)      1024	   activation_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)	 (None, 248, 256)      0	   batchnormalization_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 244, 512)      655872	   maxpooling1d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)	 (None, 244, 512)      0	   convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 244, 512)      2048	   activation_3[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)	 (None, 122, 512)      0	   batchnormalization_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 118, 512)      1311232	   maxpooling1d_3[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)	 (None, 118, 512)      0	   convolution1d_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_4 (MaxPooling1D)	 (None, 59, 512)       0	   activation_4[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)		 (None, 30208)	       0	   maxpooling1d_4[0][0]
____________________________________________________________________________________________________
dense_1 (Dense) 		 (None, 1024)	       30934016    flatten_1[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)	 (None, 1024)	       0	   dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 1024)	       4096	   activation_5[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)		 (None, 1024)	       0	   batchnormalization_4[0][0]
____________________________________________________________________________________________________
dense_2 (Dense) 		 (None, 919)	       941975	   dropout_1[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)	 (None, 919)	       0	   dense_2[0][0]
====================================================================================================
Total params: 33,950,999
Trainable params: 33,947,159
Non-trainable params: 3,840
____________________________________________________________________________________________________

Running at most 70 epochs
The date is 02/06/2017
The time is 08:35:39 PM

Run `tensorboard --logdir=` to open tensorboard at (default) 127.0.0.1:6006
Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06677--acc::0.9800Epoch 00000: val_loss improved from inf to 0.05734, saving model to models/weights/conv_net_8.hdf5

Retrieving train, validation, and test data
Building the model
Compiling model
Saving models in json and yaml format to models/json/conv_net_8.json and  models/yaml/conv_net_8.yaml
Saving weights to models/weights/conv_net_8.hdf5 and epoch logs to logs/half_set/conv_net_8.csv
Saving models/json/conv_net_8.json to models/json/conv_net_8.json.old
Saving models/yaml/conv_net_8.yaml to models/yaml/conv_net_8.yaml.old
Loading weights from models/weights/conv_net_8.hdf5 if it exists

Retrieving train, validation, and test data
Building the model
Compiling model
Saving models in json and yaml format to models/json/conv_net_8.json and  models/yaml/conv_net_8.yaml
Saving weights to models/weights/conv_net_8.hdf5 and epoch logs to logs/half_set/conv_net_8.csv
Saving models/json/conv_net_8.json to models/json/conv_net_8.json.old
Saving models/yaml/conv_net_8.yaml to models/yaml/conv_net_8.yaml.old
Loading weights from models/weights/conv_net_8.hdf5 if it exists
Saving logs/half_set/conv_net_8.csv to logs/half_set/conv_net_8.csv.old
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 128)      1664	   convolution1d_input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 998, 128)      0	   convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 128)      512	   activation_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)	 (None, 499, 128)      0	   batchnormalization_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 497, 256)      98560	   maxpooling1d_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)	 (None, 497, 256)      0	   convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 497, 256)      1024	   activation_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)	 (None, 248, 256)      0	   batchnormalization_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 244, 512)      655872	   maxpooling1d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)	 (None, 244, 512)      0	   convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 244, 512)      2048	   activation_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 240, 512)      1311232	   batchnormalization_3[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)	 (None, 240, 512)      0	   convolution1d_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)	 (None, 120, 512)      0	   activation_4[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)		 (None, 61440)	       0	   maxpooling1d_3[0][0]
____________________________________________________________________________________________________
dense_1 (Dense) 		 (None, 1024)	       62915584    flatten_1[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)	 (None, 1024)	       0	   dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 1024)	       4096	   activation_5[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)		 (None, 1024)	       0	   batchnormalization_4[0][0]
____________________________________________________________________________________________________
dense_2 (Dense) 		 (None, 919)	       941975	   dropout_1[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)	 (None, 919)	       0	   dense_2[0][0]
====================================================================================================
Total params: 65,932,567
Trainable params: 65,928,727
Non-trainable params: 3,840
____________________________________________________________________________________________________

Running at most 70 epochs
The date is 02/06/2017
The time is 09:29:17 PM

Run `tensorboard --logdir=` to open tensorboard at (default) 127.0.0.1:6006
Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
1149600/2200000 [==============>...............] - ETA: 1210ss--loss::0.08194--acc::0.97645

Retrieving train, validation, and test data
Building the model
Compiling model
Saving models in json and yaml format to models/json/conv_net_8.json and  models/yaml/conv_net_8.yaml
Saving weights to models/weights/conv_net_8.hdf5 and epoch logs to logs/half_set/conv_net_8.csv
Saving models/json/conv_net_8.json to models/json/conv_net_8.json.old
Saving models/yaml/conv_net_8.yaml to models/yaml/conv_net_8.yaml.old
Loading weights from models/weights/conv_net_8.hdf5 if it exists
Saving logs/half_set/conv_net_8.csv to logs/half_set/conv_net_8.csv.old
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 128)      1664	   convolution1d_input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 998, 128)      0	   convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 128)      512	   activation_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)	 (None, 499, 128)      0	   batchnormalization_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 497, 256)      98560	   maxpooling1d_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)	 (None, 497, 256)      0	   convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 497, 256)      1024	   activation_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)	 (None, 248, 256)      0	   batchnormalization_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 244, 512)      655872	   maxpooling1d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)	 (None, 244, 512)      0	   convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 244, 512)      2048	   activation_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 240, 512)      1311232	   batchnormalization_3[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)	 (None, 240, 512)      0	   convolution1d_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)	 (None, 120, 512)      0	   activation_4[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)		 (None, 61440)	       0	   maxpooling1d_3[0][0]
____________________________________________________________________________________________________
dense_1 (Dense) 		 (None, 1024)	       62915584    flatten_1[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)	 (None, 1024)	       0	   dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 1024)	       4096	   activation_5[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)		 (None, 1024)	       0	   batchnormalization_4[0][0]
____________________________________________________________________________________________________
dense_2 (Dense) 		 (None, 919)	       941975	   dropout_1[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)	 (None, 919)	       0	   dense_2[0][0]
====================================================================================================
Total params: 65,932,567
Trainable params: 65,928,727
Non-trainable params: 3,840
____________________________________________________________________________________________________

Running at most 70 epochs
The date is 02/06/2017
The time is 10:04:20 PM

Run `tensorboard --logdir=logs/tensorboard` to open tensorboard at (default) 127.0.0.1:6006
Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.07366--acc::0.9791Epoch 00000: val_loss improved from inf to 0.06074, saving model to models/weights/conv_net_8.hdf5


Retrieving train, validation, and test data
Building the model
Compiling model
Saving models in json and yaml format to models/json/conv_net_8.json and  models/yaml/conv_net_8.yaml
Saving weights to models/weights/conv_net_8.hdf5 and epoch logs to logs/half_set/conv_net_8.csv
Saving models/json/conv_net_8.json to models/json/conv_net_8.json.old
Saving models/yaml/conv_net_8.yaml to models/yaml/conv_net_8.yaml.old
Loading weights from models/weights/conv_net_8.hdf5 if it exists
Saving models/weights/conv_net_8.hdf5 to models/weights/conv_net_8.hdf5.old
Saving logs/half_set/conv_net_8.csv to logs/half_set/conv_net_8.csv.old
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 128)      1664	   convolution1d_input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 998, 128)      0	   convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 128)      512	   activation_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)	 (None, 499, 128)      0	   batchnormalization_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 497, 256)      98560	   maxpooling1d_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)	 (None, 497, 256)      0	   convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 497, 256)      1024	   activation_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)	 (None, 248, 256)      0	   batchnormalization_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 244, 512)      655872	   maxpooling1d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)	 (None, 244, 512)      0	   convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 244, 512)      2048	   activation_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 240, 512)      1311232	   batchnormalization_3[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)	 (None, 240, 512)      0	   convolution1d_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)	 (None, 120, 512)      0	   activation_4[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)		 (None, 61440)	       0	   maxpooling1d_3[0][0]
____________________________________________________________________________________________________
dense_1 (Dense) 		 (None, 1024)	       62915584    flatten_1[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)	 (None, 1024)	       0	   dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 1024)	       4096	   activation_5[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)		 (None, 1024)	       0	   batchnormalization_4[0][0]
____________________________________________________________________________________________________
dense_2 (Dense) 		 (None, 919)	       941975	   dropout_1[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)	 (None, 919)	       0	   dense_2[0][0]
====================================================================================================
Total params: 65,932,567
Trainable params: 65,928,727
Non-trainable params: 3,840
____________________________________________________________________________________________________

Running at most 70 epochs
The date is 02/06/2017
The time is 10:51:48 PM


Retrieving train, validation, and test data
Building the model
Compiling model
Saving models in json and yaml format to models/json/conv_net_8.json and  models/yaml/conv_net_8.yaml
Saving weights to models/weights/conv_net_8.hdf5 and epoch logs to logs/half_set/conv_net_8.csv
Saving models/json/conv_net_8.json to models/json/conv_net_8.json.old
Saving models/yaml/conv_net_8.yaml to models/yaml/conv_net_8.yaml.old
Loading weights from models/weights/conv_net_8.hdf5 if it exists
Saving models/weights/conv_net_8.hdf5 to models/weights/conv_net_8.hdf5.old
Saving logs/half_set/conv_net_8.csv to logs/half_set/conv_net_8.csv.old
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 128)      1664	   convolution1d_input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 998, 128)      0	   convolution1d_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 998, 128)      512	   activation_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)	 (None, 499, 128)      0	   batchnormalization_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 497, 256)      98560	   maxpooling1d_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)	 (None, 497, 256)      0	   convolution1d_2[0][0]
____________________________________________________________________________________________________
batchnormalization_2 (BatchNorma (None, 497, 256)      1024	   activation_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)	 (None, 248, 256)      0	   batchnormalization_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 244, 512)      655872	   maxpooling1d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)	 (None, 244, 512)      0	   convolution1d_3[0][0]
____________________________________________________________________________________________________
batchnormalization_3 (BatchNorma (None, 244, 512)      2048	   activation_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 240, 512)      1311232	   batchnormalization_3[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)	 (None, 240, 512)      0	   convolution1d_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)	 (None, 120, 512)      0	   activation_4[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)		 (None, 61440)	       0	   maxpooling1d_3[0][0]
____________________________________________________________________________________________________
dense_1 (Dense) 		 (None, 1024)	       62915584    flatten_1[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)	 (None, 1024)	       0	   dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_4 (BatchNorma (None, 1024)	       4096	   activation_5[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)		 (None, 1024)	       0	   batchnormalization_4[0][0]
____________________________________________________________________________________________________
dense_2 (Dense) 		 (None, 919)	       941975	   dropout_1[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)	 (None, 919)	       0	   dense_2[0][0]
====================================================================================================
Total params: 65,932,567
Trainable params: 65,928,727
Non-trainable params: 3,840
____________________________________________________________________________________________________

Running at most 70 epochs
The date is 02/06/2017
The time is 10:54:09 PM

Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.07099--acc::0.9795Epoch 00000: val_loss improved from inf to 0.05996, saving model to models/weights/conv_net_8.hdf5
2200000/2200000 [==============================] - 5978s - loss: 0.0709 - acc: 0.9795 - val_loss: 0.0600 - val_acc: 0.9824
Epoch 2/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.06755--acc::0.9800Epoch 00001: val_loss improved from 0.05996 to 0.05877, saving model to models/weights/conv_net_8.hdf5
2200000/2200000 [==============================] - 5978s - loss: 0.0675 - acc: 0.9800 - val_loss: 0.0588 - val_acc: 0.9826
Epoch 3/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.06566--acc::0.9804Epoch 00002: val_loss improved from 0.05877 to 0.05850, saving model to models/weights/conv_net_8.hdf5
2200000/2200000 [==============================] - 5976s - loss: 0.0656 - acc: 0.9804 - val_loss: 0.0585 - val_acc: 0.9825
Epoch 4/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.06388--acc::0.9808Epoch 00003: val_loss did not improve
2200000/2200000 [==============================] - 5975s - loss: 0.0638 - acc: 0.9808 - val_loss: 0.0598 - val_acc: 0.9822
Epoch 5/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.06244--acc::0.9811Epoch 00004: val_loss did not improve
2200000/2200000 [==============================] - 5975s - loss: 0.0624 - acc: 0.9811 - val_loss: 0.0589 - val_acc: 0.9824
Epoch 6/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.06122--acc::0.9813Epoch 00005: val_loss did not improve
2200000/2200000 [==============================] - 5974s - loss: 0.0612 - acc: 0.9813 - val_loss: 0.0599 - val_acc: 0.9821
Epoch 7/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.06033--acc::0.9815Epoch 00006: val_loss did not improve
2200000/2200000 [==============================] - 5975s - loss: 0.0603 - acc: 0.9815 - val_loss: 0.0605 - val_acc: 0.9823
Epoch 8/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.05955--acc::0.9817Epoch 00007: val_loss did not improve
2200000/2200000 [==============================] - 5973s - loss: 0.0595 - acc: 0.9817 - val_loss: 0.0606 - val_acc: 0.9822
Epoch 9/70
2199600/2200000 [============================>.] - ETA: 1ss--loss::0.05899--acc::0.9818Epoch 00008: val_loss did not improve
2200000/2200000 [==============================] - 5973s - loss: 0.0589 - acc: 0.9818 - val_loss: 0.0605 - val_acc: 0.9822
Epoch 00008: early stopping
455024/455024 [==============================] - 314s 0sss
[0.065844098324914793, 0.98090824700386081]
