
Retrieving train, validation, and test data
Building the model
Compiling model
Saving models in json and yaml format to models/json/conv_net_10.json and  models/yaml/conv_net_10.yaml
Saving weights to models/weights/conv_net_10.hdf5 and epoch logs to logs/half_set/conv_net_10.csv
Loading weights from models/weights/conv_net_10.hdf5 if it exists
____________________________________________________________________________________________________
Layer (type)			 Output Shape	       Param #	   Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 998, 128)      1664	   convolution1d_input_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)	 (None, 998, 128)      0	   convolution1d_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)	 (None, 499, 128)      0	   activation_1[0][0]
____________________________________________________________________________________________________
convolution1d_2 (Convolution1D)  (None, 497, 256)      98560	   maxpooling1d_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)	 (None, 497, 256)      0	   convolution1d_2[0][0]
____________________________________________________________________________________________________
maxpooling1d_2 (MaxPooling1D)	 (None, 248, 256)      0	   activation_2[0][0]
____________________________________________________________________________________________________
convolution1d_3 (Convolution1D)  (None, 244, 512)      655872	   maxpooling1d_2[0][0]
____________________________________________________________________________________________________
activation_3 (Activation)	 (None, 244, 512)      0	   convolution1d_3[0][0]
____________________________________________________________________________________________________
maxpooling1d_3 (MaxPooling1D)	 (None, 122, 512)      0	   activation_3[0][0]
____________________________________________________________________________________________________
convolution1d_4 (Convolution1D)  (None, 118, 512)      1311232	   maxpooling1d_3[0][0]
____________________________________________________________________________________________________
activation_4 (Activation)	 (None, 118, 512)      0	   convolution1d_4[0][0]
____________________________________________________________________________________________________
maxpooling1d_4 (MaxPooling1D)	 (None, 59, 512)       0	   activation_4[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)		 (None, 30208)	       0	   maxpooling1d_4[0][0]
____________________________________________________________________________________________________
dense_1 (Dense) 		 (None, 1024)	       30934016    flatten_1[0][0]
____________________________________________________________________________________________________
activation_5 (Activation)	 (None, 1024)	       0	   dense_1[0][0]
____________________________________________________________________________________________________
batchnormalization_1 (BatchNorma (None, 1024)	       4096	   activation_5[0][0]
____________________________________________________________________________________________________
dropout_1 (Dropout)		 (None, 1024)	       0	   batchnormalization_1[0][0]
____________________________________________________________________________________________________
dense_2 (Dense) 		 (None, 919)	       941975	   dropout_1[0][0]
____________________________________________________________________________________________________
activation_6 (Activation)	 (None, 919)	       0	   dense_2[0][0]
====================================================================================================
Total params: 33,947,415
Trainable params: 33,945,367
Non-trainable params: 2,048
____________________________________________________________________________________________________

Running at most 70 epochs
The date is 02/08/2017
The time is 01:10:42 PM

Train on 2200000 samples, validate on 8000 samples
Epoch 1/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.08022--acc::0.9784Epoch 00000: val_loss improved from inf to 0.19250, saving model to models/weights/conv_net_10.hdf5
2200000/2200000 [==============================] - 3950s - loss: 0.0802 - acc: 0.9784 - val_loss: 0.1925 - val_acc: 0.9288
Epoch 2/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.07333--acc::0.9792Epoch 00001: val_loss improved from 0.19250 to 0.07252, saving model to models/weights/conv_net_10.hdf5
2200000/2200000 [==============================] - 3950s - loss: 0.0733 - acc: 0.9792 - val_loss: 0.0725 - val_acc: 0.9801
Epoch 3/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.07177--acc::0.9794Epoch 00002: val_loss improved from 0.07252 to 0.06977, saving model to models/weights/conv_net_10.hdf5
2200000/2200000 [==============================] - 3951s - loss: 0.0717 - acc: 0.9794 - val_loss: 0.0698 - val_acc: 0.9808
Epoch 4/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06977--acc::0.9796Epoch 00003: val_loss improved from 0.06977 to 0.06077, saving model to models/weights/conv_net_10.hdf5
2200000/2200000 [==============================] - 3953s - loss: 0.0697 - acc: 0.9796 - val_loss: 0.0608 - val_acc: 0.9822
Epoch 5/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06833--acc::0.9799Epoch 00004: val_loss improved from 0.06077 to 0.05968, saving model to models/weights/conv_net_10.hdf5
2200000/2200000 [==============================] - 3951s - loss: 0.0683 - acc: 0.9799 - val_loss: 0.0597 - val_acc: 0.9826
Epoch 6/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06744--acc::0.9800Epoch 00005: val_loss did not improve
2200000/2200000 [==============================] - 3947s - loss: 0.0674 - acc: 0.9800 - val_loss: 0.0607 - val_acc: 0.9825
Epoch 7/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06677--acc::0.9801Epoch 00006: val_loss did not improve
2200000/2200000 [==============================] - 3947s - loss: 0.0667 - acc: 0.9801 - val_loss: 0.0606 - val_acc: 0.9825
Epoch 8/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06622--acc::0.9802Epoch 00007: val_loss improved from 0.05968 to 0.05812, saving model to models/weights/conv_net_10.hdf5
2200000/2200000 [==============================] - 3948s - loss: 0.0662 - acc: 0.9802 - val_loss: 0.0581 - val_acc: 0.9827
Epoch 9/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06588--acc::0.9802Epoch 00008: val_loss improved from 0.05812 to 0.05775, saving model to models/weights/conv_net_10.hdf5
2200000/2200000 [==============================] - 3949s - loss: 0.0658 - acc: 0.9802 - val_loss: 0.0578 - val_acc: 0.9828
Epoch 10/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06544--acc::0.9803Epoch 00009: val_loss improved from 0.05775 to 0.05766, saving model to models/weights/conv_net_10.hdf5
2200000/2200000 [==============================] - 3949s - loss: 0.0654 - acc: 0.9803 - val_loss: 0.0577 - val_acc: 0.9828
Epoch 11/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06511--acc::0.9803Epoch 00010: val_loss did not improve
2200000/2200000 [==============================] - 3947s - loss: 0.0651 - acc: 0.9803 - val_loss: 0.0585 - val_acc: 0.9826
Epoch 12/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06488--acc::0.9804Epoch 00011: val_loss did not improve
2200000/2200000 [==============================] - 3947s - loss: 0.0648 - acc: 0.9804 - val_loss: 0.0581 - val_acc: 0.9828
Epoch 13/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06466--acc::0.9804Epoch 00012: val_loss improved from 0.05766 to 0.05737, saving model to models/weights/conv_net_10.hdf5
2200000/2200000 [==============================] - 3948s - loss: 0.0646 - acc: 0.9804 - val_loss: 0.0574 - val_acc: 0.9828
Epoch 14/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06444--acc::0.9805Epoch 00013: val_loss did not improve
2200000/2200000 [==============================] - 3947s - loss: 0.0644 - acc: 0.9805 - val_loss: 0.0583 - val_acc: 0.9826
Epoch 15/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06422--acc::0.9805Epoch 00014: val_loss did not improve
2200000/2200000 [==============================] - 3947s - loss: 0.0642 - acc: 0.9805 - val_loss: 0.0579 - val_acc: 0.9826
Epoch 16/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06400--acc::0.9806Epoch 00015: val_loss did not improve
2200000/2200000 [==============================] - 3947s - loss: 0.0640 - acc: 0.9805 - val_loss: 0.0575 - val_acc: 0.9827
Epoch 17/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06399--acc::0.9806Epoch 00016: val_loss did not improve
2200000/2200000 [==============================] - 3947s - loss: 0.0639 - acc: 0.9806 - val_loss: 0.0593 - val_acc: 0.9824
Epoch 18/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06377--acc::0.9806Epoch 00017: val_loss did not improve
2200000/2200000 [==============================] - 3948s - loss: 0.0637 - acc: 0.9806 - val_loss: 0.0577 - val_acc: 0.9827
Epoch 19/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06366--acc::0.9806Epoch 00018: val_loss improved from 0.05737 to 0.05688, saving model to models/weights/conv_net_10.hdf5
2200000/2200000 [==============================] - 3948s - loss: 0.0636 - acc: 0.9806 - val_loss: 0.0569 - val_acc: 0.9828
Epoch 20/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06355--acc::0.9807Epoch 00019: val_loss did not improve
2200000/2200000 [==============================] - 3947s - loss: 0.0635 - acc: 0.9807 - val_loss: 0.0579 - val_acc: 0.9827
Epoch 21/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06344--acc::0.9807Epoch 00020: val_loss did not improve
2200000/2200000 [==============================] - 3947s - loss: 0.0634 - acc: 0.9807 - val_loss: 0.0577 - val_acc: 0.9827
Epoch 22/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06333--acc::0.9807Epoch 00021: val_loss did not improve
2200000/2200000 [==============================] - 3947s - loss: 0.0633 - acc: 0.9807 - val_loss: 0.0583 - val_acc: 0.9825
Epoch 23/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06322--acc::0.9807Epoch 00022: val_loss did not improve
2200000/2200000 [==============================] - 3947s - loss: 0.0632 - acc: 0.9807 - val_loss: 0.0574 - val_acc: 0.9826
Epoch 24/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06311--acc::0.9808Epoch 00023: val_loss did not improve
2200000/2200000 [==============================] - 3952s - loss: 0.0631 - acc: 0.9808 - val_loss: 0.0582 - val_acc: 0.9825
Epoch 25/70
2199600/2200000 [============================>.] - ETA: 0ss--loss::0.06299--acc::0.9808Epoch 00024: val_loss did not improve
2200000/2200000 [==============================] - 3954s - loss: 0.0629 - acc: 0.9808 - val_loss: 0.0581 - val_acc: 0.9826
Epoch 00024: early stopping
455008/455024 [============================>.] - ETA: 0s: 
[0.062665412667565645, 0.98118000701785046]

