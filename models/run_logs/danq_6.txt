Creating model from DanQ()
Building the model
Compiling model
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to
====================================================================================================
convolution1d_1 (Convolution1D)  (None, 975, 320)      33600       convolution1d_input_1[0][0]
____________________________________________________________________________________________________
maxpooling1d_1 (MaxPooling1D)    (None, 75, 320)       0           convolution1d_1[0][0]
____________________________________________________________________________________________________
bidirectional_1 (Bidirectional)  (None, 75, 512)       886272      maxpooling1d_1[0][0]
____________________________________________________________________________________________________
flatten_1 (Flatten)              (None, 38400)         0           bidirectional_1[0][0]
____________________________________________________________________________________________________
dense_1 (Dense)                  (None, 925)           35520925    flatten_1[0][0]
____________________________________________________________________________________________________
activation_1 (Activation)        (None, 925)           0           dense_1[0][0]
____________________________________________________________________________________________________
dense_2 (Dense)                  (None, 919)           850994      activation_1[0][0]
____________________________________________________________________________________________________
activation_2 (Activation)        (None, 919)           0           dense_2[0][0]
====================================================================================================
Total params: 37,291,791
Trainable params: 37,291,791
Non-trainable params: 0
____________________________________________________________________________________________________
Saving models in json and yaml format to models/json/danq_6.json and  models/yaml/danq_6.yaml
Saving weights to models/weights/danq_6.hdf5 and epoch logs to models/csv/danq_6.csv
Retrieving train, validation, and test data

The date is 02/26/2017
The time is 01:44:30 PM

Running at most 70 epochs
Epoch 1/70
2199900/2200000 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9790Epoch 00000: val_loss improved from inf to 0.06995, saving model to models/weights/danq_6.hdf5
2200000/2200000 [==============================] - 3834s - loss: 0.0791 - acc: 0.9790 - val_loss: 0.0700 - val_acc: 0.9813
Epoch 2/70
2199900/2200000 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9790Epoch 00001: val_loss did not improve
2200000/2200000 [==============================] - 3820s - loss: 0.0784 - acc: 0.9790 - val_loss: 0.0704 - val_acc: 0.9812
Epoch 3/70
2199900/2200000 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9791Epoch 00002: val_loss did not improve
2200000/2200000 [==============================] - 3813s - loss: 0.0789 - acc: 0.9791 - val_loss: 0.0702 - val_acc: 0.9813
Epoch 4/70
2199900/2200000 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9792Epoch 00003: val_loss improved from 0.06995 to 0.06741, saving model to models/weights/danq_6.hdf5
2200000/2200000 [==============================] - 3813s - loss: 0.0776 - acc: 0.9792 - val_loss: 0.0674 - val_acc: 0.9814
