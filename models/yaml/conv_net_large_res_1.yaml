class_name: Model
config:
  input_layers:
  - [input_1, 0, 0]
  layers:
  - class_name: InputLayer
    config:
      batch_input_shape: !!python/tuple [null, 1000, 4]
      input_dtype: float32
      name: input_1
      sparse: false
    inbound_nodes: []
    name: input_1
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: null
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      batch_input_shape: !!python/tuple [null, 1000, 4]
      bias: true
      border_mode: valid
      filter_length: 3
      init: he_normal
      input_dim: 4
      input_dtype: float32
      input_length: 1000
      name: convolution1d_1
      nb_filter: 64
      subsample_length: 1
      trainable: true
    inbound_nodes:
    - - [input_1, 0, 0]
    name: convolution1d_1
  - class_name: Activation
    config: {activation: relu, name: activation_1, trainable: true}
    inbound_nodes:
    - - [convolution1d_1, 0, 0]
    name: activation_1
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: batchnormalization_1, trainable: true}
    inbound_nodes:
    - - [activation_1, 0, 0]
    name: batchnormalization_1
  - class_name: MaxPooling1D
    config: {border_mode: valid, name: maxpooling1d_1, pool_length: 2, stride: 2,
      trainable: true}
    inbound_nodes:
    - - [batchnormalization_1, 0, 0]
    name: maxpooling1d_1
  - class_name: Convolution1D
    config: {W_constraint: null, W_regularizer: null, activation: linear, activity_regularizer: null,
      b_constraint: null, b_regularizer: null, bias: true, border_mode: valid, filter_length: 3,
      init: he_normal, input_dim: null, input_length: null, name: convolution1d_2,
      nb_filter: 64, subsample_length: 1, trainable: true}
    inbound_nodes:
    - - [maxpooling1d_1, 0, 0]
    name: convolution1d_2
  - class_name: Activation
    config: {activation: relu, name: activation_2, trainable: true}
    inbound_nodes:
    - - [convolution1d_2, 0, 0]
    name: activation_2
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: batchnormalization_2, trainable: true}
    inbound_nodes:
    - - [activation_2, 0, 0]
    name: batchnormalization_2
  - class_name: Dropout
    config: {name: dropout_1, p: 0.2, trainable: true}
    inbound_nodes:
    - - [batchnormalization_2, 0, 0]
    name: dropout_1
  - class_name: MaxPooling1D
    config: {border_mode: valid, name: maxpooling1d_2, pool_length: 2, stride: 2,
      trainable: true}
    inbound_nodes:
    - - [dropout_1, 0, 0]
    name: maxpooling1d_2
  - class_name: Convolution1D
    config: {W_constraint: null, W_regularizer: null, activation: linear, activity_regularizer: null,
      b_constraint: null, b_regularizer: null, bias: true, border_mode: valid, filter_length: 3,
      init: he_normal, input_dim: null, input_length: null, name: convolution1d_3,
      nb_filter: 128, subsample_length: 1, trainable: true}
    inbound_nodes:
    - - [maxpooling1d_2, 0, 0]
    name: convolution1d_3
  - class_name: Activation
    config: {activation: relu, name: activation_3, trainable: true}
    inbound_nodes:
    - - [convolution1d_3, 0, 0]
    name: activation_3
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: batchnormalization_3, trainable: true}
    inbound_nodes:
    - - [activation_3, 0, 0]
    name: batchnormalization_3
  - class_name: Convolution1D
    config: {W_constraint: null, W_regularizer: null, activation: linear, activity_regularizer: null,
      b_constraint: null, b_regularizer: null, bias: true, border_mode: valid, filter_length: 3,
      init: he_normal, input_dim: null, input_length: null, name: convolution1d_4,
      nb_filter: 128, subsample_length: 1, trainable: true}
    inbound_nodes:
    - - [batchnormalization_3, 0, 0]
    name: convolution1d_4
  - class_name: Activation
    config: {activation: relu, name: activation_4, trainable: true}
    inbound_nodes:
    - - [convolution1d_4, 0, 0]
    name: activation_4
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: batchnormalization_4, trainable: true}
    inbound_nodes:
    - - [activation_4, 0, 0]
    name: batchnormalization_4
  - class_name: Dropout
    config: {name: dropout_2, p: 0.2, trainable: true}
    inbound_nodes:
    - - [batchnormalization_4, 0, 0]
    name: dropout_2
  - class_name: MaxPooling1D
    config: {border_mode: valid, name: maxpooling1d_3, pool_length: 2, stride: 2,
      trainable: true}
    inbound_nodes:
    - - [dropout_2, 0, 0]
    name: maxpooling1d_3
  - class_name: Convolution1D
    config: {W_constraint: null, W_regularizer: null, activation: linear, activity_regularizer: null,
      b_constraint: null, b_regularizer: null, bias: true, border_mode: valid, filter_length: 3,
      init: he_normal, input_dim: null, input_length: null, name: convolution1d_5,
      nb_filter: 256, subsample_length: 1, trainable: true}
    inbound_nodes:
    - - [maxpooling1d_3, 0, 0]
    name: convolution1d_5
  - class_name: Activation
    config: {activation: relu, name: activation_5, trainable: true}
    inbound_nodes:
    - - [convolution1d_5, 0, 0]
    name: activation_5
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: batchnormalization_5, trainable: true}
    inbound_nodes:
    - - [activation_5, 0, 0]
    name: batchnormalization_5
  - class_name: Dropout
    config: {name: dropout_3, p: 0.2, trainable: true}
    inbound_nodes:
    - - [batchnormalization_5, 0, 0]
    name: dropout_3
  - class_name: Convolution1D
    config: {W_constraint: null, W_regularizer: null, activation: linear, activity_regularizer: null,
      b_constraint: null, b_regularizer: null, bias: true, border_mode: valid, filter_length: 3,
      init: he_normal, input_dim: null, input_length: null, name: convolution1d_6,
      nb_filter: 256, subsample_length: 1, trainable: true}
    inbound_nodes:
    - - [dropout_3, 0, 0]
    name: convolution1d_6
  - class_name: Activation
    config: {activation: relu, name: activation_6, trainable: true}
    inbound_nodes:
    - - [convolution1d_6, 0, 0]
    name: activation_6
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: batchnormalization_6, trainable: true}
    inbound_nodes:
    - - [activation_6, 0, 0]
    name: batchnormalization_6
  - class_name: Dropout
    config: {name: dropout_4, p: 0.2, trainable: true}
    inbound_nodes:
    - - [batchnormalization_6, 0, 0]
    name: dropout_4
  - class_name: MaxPooling1D
    config: {border_mode: valid, name: maxpooling1d_4, pool_length: 2, stride: 2,
      trainable: true}
    inbound_nodes:
    - - [dropout_4, 0, 0]
    name: maxpooling1d_4
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: batchnormalization_7, trainable: true}
    inbound_nodes:
    - - [maxpooling1d_4, 0, 0]
    name: batchnormalization_7
  - class_name: Activation
    config: {activation: relu, name: activation_7, trainable: true}
    inbound_nodes:
    - - [batchnormalization_7, 0, 0]
    name: activation_7
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 3
      init: he_normal
      input_dim: null
      input_length: null
      name: convolution1d_7
      nb_filter: 64
      subsample_length: 2
      trainable: true
    inbound_nodes:
    - - [activation_7, 0, 0]
    name: convolution1d_7
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: batchnormalization_8, trainable: true}
    inbound_nodes:
    - - [convolution1d_7, 0, 0]
    name: batchnormalization_8
  - class_name: Activation
    config: {activation: relu, name: activation_8, trainable: true}
    inbound_nodes:
    - - [batchnormalization_8, 0, 0]
    name: activation_8
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 3
      init: he_normal
      input_dim: null
      input_length: null
      name: convolution1d_8
      nb_filter: 64
      subsample_length: 1
      trainable: true
    inbound_nodes:
    - - [activation_8, 0, 0]
    name: convolution1d_8
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 1
      init: he_normal
      input_dim: null
      input_length: null
      name: convolution1d_9
      nb_filter: 64
      subsample_length: 2
      trainable: true
    inbound_nodes:
    - - [activation_7, 0, 0]
    name: convolution1d_9
  - class_name: Merge
    config:
      arguments: {}
      concat_axis: -1
      dot_axes: -1
      mode: sum
      mode_type: raw
      name: merge_1
      output_mask: null
      output_mask_type: raw
      output_shape: null
      output_shape_type: raw
    inbound_nodes:
    - - [convolution1d_8, 0, 0]
      - [convolution1d_9, 0, 0]
    name: merge_1
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: batchnormalization_9, trainable: true}
    inbound_nodes:
    - - [merge_1, 0, 0]
    name: batchnormalization_9
  - class_name: Activation
    config: {activation: relu, name: activation_9, trainable: true}
    inbound_nodes:
    - - [batchnormalization_9, 0, 0]
    name: activation_9
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 3
      init: he_normal
      input_dim: null
      input_length: null
      name: convolution1d_10
      nb_filter: 64
      subsample_length: 1
      trainable: true
    inbound_nodes:
    - - [activation_9, 0, 0]
    name: convolution1d_10
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: batchnormalization_10, trainable: true}
    inbound_nodes:
    - - [convolution1d_10, 0, 0]
    name: batchnormalization_10
  - class_name: Activation
    config: {activation: relu, name: activation_10, trainable: true}
    inbound_nodes:
    - - [batchnormalization_10, 0, 0]
    name: activation_10
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 3
      init: he_normal
      input_dim: null
      input_length: null
      name: convolution1d_11
      nb_filter: 64
      subsample_length: 1
      trainable: true
    inbound_nodes:
    - - [activation_10, 0, 0]
    name: convolution1d_11
  - class_name: Merge
    config:
      arguments: {}
      concat_axis: -1
      dot_axes: -1
      mode: sum
      mode_type: raw
      name: merge_2
      output_mask: null
      output_mask_type: raw
      output_shape: null
      output_shape_type: raw
    inbound_nodes:
    - - [convolution1d_11, 0, 0]
      - [merge_1, 0, 0]
    name: merge_2
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: batchnormalization_11, trainable: true}
    inbound_nodes:
    - - [merge_2, 0, 0]
    name: batchnormalization_11
  - class_name: Activation
    config: {activation: relu, name: activation_11, trainable: true}
    inbound_nodes:
    - - [batchnormalization_11, 0, 0]
    name: activation_11
  - class_name: MaxPooling1D
    config: {border_mode: valid, name: maxpooling1d_5, pool_length: 2, stride: 2,
      trainable: true}
    inbound_nodes:
    - - [activation_11, 0, 0]
    name: maxpooling1d_5
  - class_name: Bidirectional
    config:
      layer:
        class_name: GRU
        config:
          U_regularizer: null
          W_regularizer: null
          activation: tanh
          b_regularizer: null
          batch_input_shape: !!python/tuple [null, null, 256]
          consume_less: cpu
          dropout_U: 0.5
          dropout_W: 0.2
          go_backwards: false
          init: glorot_uniform
          inner_activation: hard_sigmoid
          inner_init: orthogonal
          input_dim: 256
          input_dtype: float32
          input_length: null
          name: gru_1
          output_dim: 256
          return_sequences: true
          stateful: false
          trainable: true
          unroll: false
      merge_mode: concat
      name: bidirectional_1
      trainable: true
    inbound_nodes:
    - - [maxpooling1d_5, 0, 0]
    name: bidirectional_1
  - class_name: Flatten
    config: {name: flatten_1, trainable: true}
    inbound_nodes:
    - - [bidirectional_1, 0, 0]
    name: flatten_1
  - class_name: Dense
    config:
      W_constraint: null
      W_regularizer: null
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      batch_input_shape: !!python/tuple [null, 4096]
      bias: true
      init: he_normal
      input_dim: !!python/object/apply:numpy.core.multiarray.scalar
      - !!python/object/apply:numpy.dtype
        args: [i8, 0, 1]
        state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
      - !!binary |
        AB4AAAAAAAA=
      input_dtype: float32
      name: dense_1
      output_dim: 1024
      trainable: true
    inbound_nodes:
    - - [flatten_1, 0, 0]
    name: dense_1
  - class_name: Activation
    config: {activation: relu, name: activation_12, trainable: true}
    inbound_nodes:
    - - [dense_1, 0, 0]
    name: activation_12
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: batchnormalization_12, trainable: true}
    inbound_nodes:
    - - [activation_12, 0, 0]
    name: batchnormalization_12
  - class_name: Dropout
    config: {name: dropout_5, p: 0.5, trainable: true}
    inbound_nodes:
    - - [batchnormalization_12, 0, 0]
    name: dropout_5
  - class_name: Dense
    config:
      W_constraint: null
      W_regularizer: null
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      batch_input_shape: !!python/tuple [null, 1024]
      bias: true
      init: he_normal
      input_dim: 1024
      input_dtype: float32
      name: dense_2
      output_dim: 919
      trainable: true
    inbound_nodes:
    - - [dropout_5, 0, 0]
    name: dense_2
  - class_name: Activation
    config: {activation: sigmoid, name: activation_13, trainable: true}
    inbound_nodes:
    - - [dense_2, 0, 0]
    name: activation_13
  name: model_1
  output_layers:
  - [activation_13, 0, 0]
keras_version: 1.2.2
