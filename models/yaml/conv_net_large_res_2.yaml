class_name: Model
config:
  input_layers:
  - [input, 0, 0]
  layers:
  - class_name: InputLayer
    config:
      batch_input_shape: !!python/tuple [null, 1000, 4]
      input_dtype: float32
      name: input
      sparse: false
    inbound_nodes: []
    name: input
  - class_name: Convolution1D
    config: {W_constraint: null, W_regularizer: null, activation: linear, activity_regularizer: null,
      b_constraint: null, b_regularizer: null, bias: true, border_mode: valid, filter_length: 3,
      init: he_normal, input_dim: null, input_length: null, name: block1_conv1, nb_filter: 64,
      subsample_length: 1, trainable: true}
    inbound_nodes:
    - - [input, 0, 0]
    name: block1_conv1
  - class_name: PReLU
    config: {init: zero, name: block1_prelu1, trainable: true}
    inbound_nodes:
    - - [block1_conv1, 0, 0]
    name: block1_prelu1
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: block1_batchnorm1, trainable: true}
    inbound_nodes:
    - - [block1_prelu1, 0, 0]
    name: block1_batchnorm1
  - class_name: MaxPooling1D
    config: {border_mode: valid, name: block1_pool1, pool_length: 2, stride: 2, trainable: true}
    inbound_nodes:
    - - [block1_batchnorm1, 0, 0]
    name: block1_pool1
  - class_name: Convolution1D
    config: {W_constraint: null, W_regularizer: null, activation: linear, activity_regularizer: null,
      b_constraint: null, b_regularizer: null, bias: true, border_mode: valid, filter_length: 3,
      init: he_normal, input_dim: null, input_length: null, name: block1_conv2, nb_filter: 64,
      subsample_length: 1, trainable: true}
    inbound_nodes:
    - - [block1_pool1, 0, 0]
    name: block1_conv2
  - class_name: PReLU
    config: {init: zero, name: block1_prelu2, trainable: true}
    inbound_nodes:
    - - [block1_conv2, 0, 0]
    name: block1_prelu2
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: block1_batchnorm2, trainable: true}
    inbound_nodes:
    - - [block1_prelu2, 0, 0]
    name: block1_batchnorm2
  - class_name: MaxPooling1D
    config: {border_mode: valid, name: block1_pool2, pool_length: 2, stride: 2, trainable: true}
    inbound_nodes:
    - - [block1_batchnorm2, 0, 0]
    name: block1_pool2
  - class_name: Convolution1D
    config: {W_constraint: null, W_regularizer: null, activation: linear, activity_regularizer: null,
      b_constraint: null, b_regularizer: null, bias: true, border_mode: valid, filter_length: 3,
      init: he_normal, input_dim: null, input_length: null, name: block2_conv1, nb_filter: 128,
      subsample_length: 1, trainable: true}
    inbound_nodes:
    - - [block1_pool2, 0, 0]
    name: block2_conv1
  - class_name: PReLU
    config: {init: zero, name: block2_prelu1, trainable: true}
    inbound_nodes:
    - - [block2_conv1, 0, 0]
    name: block2_prelu1
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: block2_batchnorm1, trainable: true}
    inbound_nodes:
    - - [block2_prelu1, 0, 0]
    name: block2_batchnorm1
  - class_name: Convolution1D
    config: {W_constraint: null, W_regularizer: null, activation: linear, activity_regularizer: null,
      b_constraint: null, b_regularizer: null, bias: true, border_mode: valid, filter_length: 3,
      init: he_normal, input_dim: null, input_length: null, name: block2_conv2, nb_filter: 128,
      subsample_length: 1, trainable: true}
    inbound_nodes:
    - - [block2_batchnorm1, 0, 0]
    name: block2_conv2
  - class_name: PReLU
    config: {init: zero, name: block2_prelu2, trainable: true}
    inbound_nodes:
    - - [block2_conv2, 0, 0]
    name: block2_prelu2
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: block2_batchnorm2, trainable: true}
    inbound_nodes:
    - - [block2_prelu2, 0, 0]
    name: block2_batchnorm2
  - class_name: Dropout
    config: {name: block2_dropout1, p: 0.2, trainable: true}
    inbound_nodes:
    - - [block2_batchnorm2, 0, 0]
    name: block2_dropout1
  - class_name: MaxPooling1D
    config: {border_mode: valid, name: block2_pool1, pool_length: 2, stride: 2, trainable: true}
    inbound_nodes:
    - - [block2_dropout1, 0, 0]
    name: block2_pool1
  - class_name: Convolution1D
    config: {W_constraint: null, W_regularizer: null, activation: linear, activity_regularizer: null,
      b_constraint: null, b_regularizer: null, bias: true, border_mode: valid, filter_length: 3,
      init: he_normal, input_dim: null, input_length: null, name: block3_conv1, nb_filter: 256,
      subsample_length: 1, trainable: true}
    inbound_nodes:
    - - [block2_pool1, 0, 0]
    name: block3_conv1
  - class_name: PReLU
    config: {init: zero, name: block3_prelu1, trainable: true}
    inbound_nodes:
    - - [block3_conv1, 0, 0]
    name: block3_prelu1
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: block3_batchnorm1, trainable: true}
    inbound_nodes:
    - - [block3_prelu1, 0, 0]
    name: block3_batchnorm1
  - class_name: Dropout
    config: {name: block3_dropout1, p: 0.2, trainable: true}
    inbound_nodes:
    - - [block3_batchnorm1, 0, 0]
    name: block3_dropout1
  - class_name: Convolution1D
    config: {W_constraint: null, W_regularizer: null, activation: linear, activity_regularizer: null,
      b_constraint: null, b_regularizer: null, bias: true, border_mode: valid, filter_length: 3,
      init: he_normal, input_dim: null, input_length: null, name: block3_conv2, nb_filter: 256,
      subsample_length: 1, trainable: true}
    inbound_nodes:
    - - [block3_dropout1, 0, 0]
    name: block3_conv2
  - class_name: PReLU
    config: {init: zero, name: block3_prelu2, trainable: true}
    inbound_nodes:
    - - [block3_conv2, 0, 0]
    name: block3_prelu2
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: block3_batchnorm2, trainable: true}
    inbound_nodes:
    - - [block3_prelu2, 0, 0]
    name: block3_batchnorm2
  - class_name: Dropout
    config: {name: block3_dropout2, p: 0.2, trainable: true}
    inbound_nodes:
    - - [block3_batchnorm2, 0, 0]
    name: block3_dropout2
  - class_name: MaxPooling1D
    config: {border_mode: valid, name: block3_pool1, pool_length: 2, stride: 2, trainable: true}
    inbound_nodes:
    - - [block3_dropout2, 0, 0]
    name: block3_pool1
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: wide_res_batchnorm1_block1_0_1, trainable: true}
    inbound_nodes:
    - - [block3_pool1, 0, 0]
    name: wide_res_batchnorm1_block1_0_1
  - class_name: Activation
    config: {activation: relu, name: wide_res_relu1_block1_0_1, trainable: true}
    inbound_nodes:
    - - [wide_res_batchnorm1_block1_0_1, 0, 0]
    name: wide_res_relu1_block1_0_1
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 3
      init: he_normal
      input_dim: null
      input_length: null
      name: wide_res_conv1_block1_0_1
      nb_filter: 64
      subsample_length: 1
      trainable: true
    inbound_nodes:
    - - [wide_res_relu1_block1_0_1, 0, 0]
    name: wide_res_conv1_block1_0_1
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: wide_res_batchnorm1_block1_1_1, trainable: true}
    inbound_nodes:
    - - [wide_res_conv1_block1_0_1, 0, 0]
    name: wide_res_batchnorm1_block1_1_1
  - class_name: Activation
    config: {activation: relu, name: wide_res_relu1_block1_1_1, trainable: true}
    inbound_nodes:
    - - [wide_res_batchnorm1_block1_1_1, 0, 0]
    name: wide_res_relu1_block1_1_1
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 3
      init: he_normal
      input_dim: null
      input_length: null
      name: wide_res_conv1_block1_1_1
      nb_filter: 64
      subsample_length: 1
      trainable: true
    inbound_nodes:
    - - [wide_res_relu1_block1_1_1, 0, 0]
    name: wide_res_conv1_block1_1_1
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 1
      init: he_normal
      input_dim: null
      input_length: null
      name: wide_res_shortcut_block1_1_1
      nb_filter: 64
      subsample_length: 1
      trainable: true
    inbound_nodes:
    - - [wide_res_relu1_block1_0_1, 0, 0]
    name: wide_res_shortcut_block1_1_1
  - class_name: Merge
    config:
      arguments: {}
      concat_axis: -1
      dot_axes: -1
      mode: sum
      mode_type: raw
      name: merge_1
      output_mask: null
      output_mask_type: raw
      output_shape: null
      output_shape_type: raw
    inbound_nodes:
    - - [wide_res_conv1_block1_1_1, 0, 0]
      - [wide_res_shortcut_block1_1_1, 0, 0]
    name: merge_1
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: wide_res_batchnorm1_block1_0_2, trainable: true}
    inbound_nodes:
    - - [merge_1, 0, 0]
    name: wide_res_batchnorm1_block1_0_2
  - class_name: Activation
    config: {activation: relu, name: wide_res_relu1_block1_0_2, trainable: true}
    inbound_nodes:
    - - [wide_res_batchnorm1_block1_0_2, 0, 0]
    name: wide_res_relu1_block1_0_2
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 3
      init: he_normal
      input_dim: null
      input_length: null
      name: wide_res_conv1_block1_0_2
      nb_filter: 64
      subsample_length: 1
      trainable: true
    inbound_nodes:
    - - [wide_res_relu1_block1_0_2, 0, 0]
    name: wide_res_conv1_block1_0_2
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: wide_res_batchnorm1_block1_1_2, trainable: true}
    inbound_nodes:
    - - [wide_res_conv1_block1_0_2, 0, 0]
    name: wide_res_batchnorm1_block1_1_2
  - class_name: Activation
    config: {activation: relu, name: wide_res_relu1_block1_1_2, trainable: true}
    inbound_nodes:
    - - [wide_res_batchnorm1_block1_1_2, 0, 0]
    name: wide_res_relu1_block1_1_2
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 3
      init: he_normal
      input_dim: null
      input_length: null
      name: wide_res_conv1_block1_1_2
      nb_filter: 64
      subsample_length: 1
      trainable: true
    inbound_nodes:
    - - [wide_res_relu1_block1_1_2, 0, 0]
    name: wide_res_conv1_block1_1_2
  - class_name: Merge
    config:
      arguments: {}
      concat_axis: -1
      dot_axes: -1
      mode: sum
      mode_type: raw
      name: merge_2
      output_mask: null
      output_mask_type: raw
      output_shape: null
      output_shape_type: raw
    inbound_nodes:
    - - [wide_res_conv1_block1_1_2, 0, 0]
      - [merge_1, 0, 0]
    name: merge_2
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: wide_res_batchnorm1_block2_0_1, trainable: true}
    inbound_nodes:
    - - [merge_2, 0, 0]
    name: wide_res_batchnorm1_block2_0_1
  - class_name: Activation
    config: {activation: relu, name: wide_res_relu1_block2_0_1, trainable: true}
    inbound_nodes:
    - - [wide_res_batchnorm1_block2_0_1, 0, 0]
    name: wide_res_relu1_block2_0_1
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 3
      init: he_normal
      input_dim: null
      input_length: null
      name: wide_res_conv1_block2_0_1
      nb_filter: 128
      subsample_length: 2
      trainable: true
    inbound_nodes:
    - - [wide_res_relu1_block2_0_1, 0, 0]
    name: wide_res_conv1_block2_0_1
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: wide_res_batchnorm1_block2_1_1, trainable: true}
    inbound_nodes:
    - - [wide_res_conv1_block2_0_1, 0, 0]
    name: wide_res_batchnorm1_block2_1_1
  - class_name: Activation
    config: {activation: relu, name: wide_res_relu1_block2_1_1, trainable: true}
    inbound_nodes:
    - - [wide_res_batchnorm1_block2_1_1, 0, 0]
    name: wide_res_relu1_block2_1_1
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 3
      init: he_normal
      input_dim: null
      input_length: null
      name: wide_res_conv1_block2_1_1
      nb_filter: 128
      subsample_length: 1
      trainable: true
    inbound_nodes:
    - - [wide_res_relu1_block2_1_1, 0, 0]
    name: wide_res_conv1_block2_1_1
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 1
      init: he_normal
      input_dim: null
      input_length: null
      name: wide_res_shortcut_block2_1_1
      nb_filter: 128
      subsample_length: 2
      trainable: true
    inbound_nodes:
    - - [wide_res_relu1_block2_0_1, 0, 0]
    name: wide_res_shortcut_block2_1_1
  - class_name: Merge
    config:
      arguments: {}
      concat_axis: -1
      dot_axes: -1
      mode: sum
      mode_type: raw
      name: merge_3
      output_mask: null
      output_mask_type: raw
      output_shape: null
      output_shape_type: raw
    inbound_nodes:
    - - [wide_res_conv1_block2_1_1, 0, 0]
      - [wide_res_shortcut_block2_1_1, 0, 0]
    name: merge_3
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: wide_res_batchnorm1_block2_0_2, trainable: true}
    inbound_nodes:
    - - [merge_3, 0, 0]
    name: wide_res_batchnorm1_block2_0_2
  - class_name: Activation
    config: {activation: relu, name: wide_res_relu1_block2_0_2, trainable: true}
    inbound_nodes:
    - - [wide_res_batchnorm1_block2_0_2, 0, 0]
    name: wide_res_relu1_block2_0_2
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 3
      init: he_normal
      input_dim: null
      input_length: null
      name: wide_res_conv1_block2_0_2
      nb_filter: 128
      subsample_length: 1
      trainable: true
    inbound_nodes:
    - - [wide_res_relu1_block2_0_2, 0, 0]
    name: wide_res_conv1_block2_0_2
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: wide_res_batchnorm1_block2_1_2, trainable: true}
    inbound_nodes:
    - - [wide_res_conv1_block2_0_2, 0, 0]
    name: wide_res_batchnorm1_block2_1_2
  - class_name: Activation
    config: {activation: relu, name: wide_res_relu1_block2_1_2, trainable: true}
    inbound_nodes:
    - - [wide_res_batchnorm1_block2_1_2, 0, 0]
    name: wide_res_relu1_block2_1_2
  - class_name: Convolution1D
    config:
      W_constraint: null
      W_regularizer: {l1: 0.0, l2: 0.0005000000237487257, name: L1L2Regularizer}
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      bias: false
      border_mode: same
      filter_length: 3
      init: he_normal
      input_dim: null
      input_length: null
      name: wide_res_conv1_block2_1_2
      nb_filter: 128
      subsample_length: 1
      trainable: true
    inbound_nodes:
    - - [wide_res_relu1_block2_1_2, 0, 0]
    name: wide_res_conv1_block2_1_2
  - class_name: Merge
    config:
      arguments: {}
      concat_axis: -1
      dot_axes: -1
      mode: sum
      mode_type: raw
      name: merge_4
      output_mask: null
      output_mask_type: raw
      output_shape: null
      output_shape_type: raw
    inbound_nodes:
    - - [wide_res_conv1_block2_1_2, 0, 0]
      - [merge_3, 0, 0]
    name: merge_4
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: wide_res_net_batchnorm1, trainable: true}
    inbound_nodes:
    - - [merge_4, 0, 0]
    name: wide_res_net_batchnorm1
  - class_name: Activation
    config: {activation: relu, name: wide_res_net_relu1, trainable: true}
    inbound_nodes:
    - - [wide_res_net_batchnorm1, 0, 0]
    name: wide_res_net_relu1
  - class_name: Dropout
    config: {name: dropout1, p: 0.2, trainable: true}
    inbound_nodes:
    - - [wide_res_net_relu1, 0, 0]
    name: dropout1
  - class_name: MaxPooling1D
    config: {border_mode: valid, name: dropout1_pool1, pool_length: 2, stride: 2,
      trainable: true}
    inbound_nodes:
    - - [dropout1, 0, 0]
    name: dropout1_pool1
  - class_name: Bidirectional
    config:
      layer:
        class_name: GRU
        config:
          U_regularizer: null
          W_regularizer: null
          activation: tanh
          b_regularizer: null
          batch_input_shape: !!python/tuple [null, null, 256]
          consume_less: cpu
          dropout_U: 0.0
          dropout_W: 0.0
          go_backwards: false
          init: glorot_uniform
          inner_activation: hard_sigmoid
          inner_init: orthogonal
          input_dim: 256
          input_dtype: float32
          input_length: null
          name: gru1
          output_dim: 256
          return_sequences: true
          stateful: false
          trainable: true
          unroll: false
      merge_mode: concat
      name: bidirectional_1
      trainable: true
    inbound_nodes:
    - - [dropout1_pool1, 0, 0]
    name: bidirectional_1
  - class_name: Dropout
    config: {name: gru_dropout1, p: 0.5, trainable: true}
    inbound_nodes:
    - - [bidirectional_1, 0, 0]
    name: gru_dropout1
  - class_name: Flatten
    config: {name: flatten, trainable: true}
    inbound_nodes:
    - - [gru_dropout1, 0, 0]
    name: flatten
  - class_name: Dense
    config:
      W_constraint: null
      W_regularizer: null
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      batch_input_shape: !!python/tuple [null, 4096]
      bias: true
      init: he_normal
      input_dim: !!python/object/apply:numpy.core.multiarray.scalar
      - !!python/object/apply:numpy.dtype
        args: [i8, 0, 1]
        state: !!python/tuple [3, <, null, null, null, -1, -1, 0]
      - !!binary |
        AB4AAAAAAAA=
      input_dtype: float32
      name: fc1
      output_dim: 1024
      trainable: true
    inbound_nodes:
    - - [flatten, 0, 0]
    name: fc1
  - class_name: PReLU
    config: {init: zero, name: fc1_prelu, trainable: true}
    inbound_nodes:
    - - [fc1, 0, 0]
    name: fc1_prelu
  - class_name: BatchNormalization
    config: {axis: -1, beta_regularizer: null, epsilon: 0.001, gamma_regularizer: null,
      mode: 0, momentum: 0.99, name: fc1_batchnorm, trainable: true}
    inbound_nodes:
    - - [fc1_prelu, 0, 0]
    name: fc1_batchnorm
  - class_name: Dropout
    config: {name: fc1_dropout, p: 0.5, trainable: true}
    inbound_nodes:
    - - [fc1_batchnorm, 0, 0]
    name: fc1_dropout
  - class_name: Dense
    config:
      W_constraint: null
      W_regularizer: null
      activation: linear
      activity_regularizer: null
      b_constraint: null
      b_regularizer: null
      batch_input_shape: !!python/tuple [null, 1024]
      bias: true
      init: he_normal
      input_dim: 1024
      input_dtype: float32
      name: fc2
      output_dim: 919
      trainable: true
    inbound_nodes:
    - - [fc1_dropout, 0, 0]
    name: fc2
  - class_name: Activation
    config: {activation: sigmoid, name: fc2_sigmoid, trainable: true}
    inbound_nodes:
    - - [fc2, 0, 0]
    name: fc2_sigmoid
  name: model_1
  output_layers:
  - [fc2_sigmoid, 0, 0]
keras_version: 1.2.2
